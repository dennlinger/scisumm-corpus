query	doc_id	label
(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here	[162]	[1]
(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances it set out to classify	[10, 237, 236, 77]	[1, 1, 1, 1]
(Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms to AdaBoost which force the classifiers to agree (called Co Boosting)	[174, 247]	[1, 1]
(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents	[16]	[1]
(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined	[78, 35]	[1, 1]
(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers	[14, 25]	[1, 1]
(Mimno et al, 2009) retrieve a list of potential translations simply by selecting a small number N of the most probable words in both languages and then add the Cartesian product of these sets for every topic to a set of candidate translations	[138, 137]	[1, 1]
A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew	[0, 3, 19]	[1, 1, 1]
A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)	[23]	[1]
Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)	[62]	[1]
And Mitchell and Lapata (2008) propose a model for vector composition, focusing on the different functions that might be used to combine the constituent vectors	[21]	[1]
Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al, 2010), unsupervised learning of POS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith,2011)	[0, 18]	[1, 1]
As a benchmark VPC extraction system, we use the Charniak parser (Charniak, 2000)	[30, 19, 89]	[1, 1, 1]
As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training	[62]	[1]
As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem	[20, 2]	[1, 1]
As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)	[133, 175]	[1, 1]
As in (Foster et al, 2010), this approach works at the level of phrase pairs	[23]	[1]
At each word in the string, the Roark (2001) top-down parser provides access to the weighted set of partial analyses in the beam; the set of complete derivations consistent with these is not immediately accessible, hence additional work is required to calculate such measures	[310, 72]	[1, 1]
Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque	[0]	[1]
But equally important is the fact that this new DOP* model does not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original DOP model needs to be redressed by a correction factor to maintain this property (Bod 2003)	[86, 82, 0]	[1, 1, 1]
By this result, CCG falls in line with context-free grammars, TAG, and LCFRS, whose sets of derivational structures are all regular (Vijay-Shanker et al., 1987)	[204]	[1]
Callison-Burch et al (2006) and Koehn and Monz (2006), for example, study situations where BLEU strongly disagrees with human judgment of translation quality	[39, 140]	[1, 1]
Clarke et al (2010) and Liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while Goldwasser et al (2011) presents work on unsupervised learning	[132, 156]	[1, 1]
Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available	[9, 132]	[1, 1]
Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers	[132, 9]	[1, 1]
Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)	[0]	[1]
Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)	[0]	[1]
Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky's method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)	[6, 5, 27]	[1, 1, 1]
Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model	[26]	[1]
DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al, 2011) (Figure 1)	[94]	[1]
Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al, 2011)	[0]	[1]
Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010)	[142, 141]	[1, 1]
Entries marked with are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)	[61, 104]	[1, 1]
Evaluation results recently reported by Callison-Burch et al (2006) and Koehn and Monz (2006), revealed that, in certain cases, the BLEU metric may not be a reliable MTquality indicator	[39, 140]	[1, 1]
Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences	[61, 58, 104]	[1, 1, 1]
Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew	[33]	[1]
Following Das and Petrov (2011) and Subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics	[47]	[1]
Following Jiang et al (2008), we describe segmentation and Joint S& amp; T as below: For a given Chinese sentence appearing as a character sequence: C 1: n= C 1 C 2.	[37, 22]	[1, 1]
Following this line, (Vijay-Shanker et al, 1987) have introduced a formalism called linear context-free rewriting systems (LCFRSs) that has received much attention in later years by the community	[74]	[1]
For computing distance we used the L1-norm of the difference, which worked a bit better than the Jensen Shannon divergence between the topic vectors used in (Mimno et al, 2009)	[156]	[1]
For example, Mitchell and Lapata (2008) use their models to approximate the human ratings in their sentence similarity dataset	[180]	[1]
For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective	[0]	[1]
For instance, Callison-Burch et al (2006) and Koehn and Monz (2006) reported and analyzed several cases of strong disagreement between system rankings provided by human assessors and those produced by the BLEU metric (Papineni et al, 2001)	[39, 140]	[1, 1]
For language modeling, we computed 5-gram models using IRSTLM7 (Federico et al., 2008) and queried the model with KenLM (Heafield, 2011)	[103]	[1]
For our training and test data we used the English-French subset of the Europarl corpus provided for the shared task (Koehn and Monz, 2006) at the Statistical Machine Translation workshop held in conjunction with the 2006 HLT-NAACL conference	[9, 8]	[1, 1]
For the language model, we used the KenLM toolkit (Heafield, 2011) to create a 5-gram language model on the target side of the Europarl corpus (v7) with approximately 54M tokens with KneserNey smoothing	[199, 0]	[1, 1]
For the same reason, human evaluation metrics based on adequacy and fluency were not suitable either (Koehn and Monz, 2006)	[63, 175]	[1, 1]
For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)	[0]	[1]
Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance	[42]	[1]
Foster et al (2010) further perform this on extracted phrase pairs, not just sentences	[68, 65]	[1, 1]
Foster et al (2010) propose a similar method for machine translation that uses features to capture degrees of generality	[22, 0]	[1, 1]
Foster et al (2010), however, uses a different approach to select related sentences from OUT	[31]	[1]
Furthermore, the extraction of grammars for training is done in a leave-one-out fashion (Zollmann and Simaan,2005) where rules are extracted for a parallel sentence pair only if the same rules are found in other sentences of the corpus as well.3-gram (news-commentary) and 5-gram (Europarl) language models are trained on the data described in Table 1, using the SRILM toolkit (Stolcke, 2002) and binarized for efficient querying using kenlm (Heafield, 2011)	[12]	[1]
Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of Das and Petrov (2011). This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider	[18, 0]	[1, 1]
Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)	[23]	[1]
Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach	[0, 49]	[1, 1]
Goldberg and Tsarfaty (2008) propose a generative joint model	[0]	[1]
Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models	[0]	[1]
Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank	[134, 133]	[1, 1]
Goodman's transform, in combination with a range of heuristics, allowed Bod (2003) to run the DOP model on the Penn Treebank WSJ benchmark and obtain some of the best results obtained with a generative model	[135]	[1]
Henderson and Brill (1999) also reported that context did not help them to outperform simple voting	[84]	[1]
Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper	[120, 112, 111]	[1, 1, 1]
Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined	[78, 35]	[1, 1]
Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees	[67]	[1]
Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy	[1, 111]	[1, 1]
In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification	[18, 250, 0]	[1, 1, 1]
In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT	[42]	[1]
In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)	[26]	[1]
In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))	[188, 111]	[1, 1]
In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense	[81]	[1]
In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)	[175]	[1]
In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees	[20]	[1]
In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)'s parser, (McDonald et al., 2006)'s parser, and so on	[45]	[1]
In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)	[0]	[1]
In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance	[132, 9]	[1, 1]
In previously reported work, (Mimno et al, 2009) evaluate parallel document retrieval using PLTM on Europarl speeches in English and Spanish, using training and test sets of size similar to ours	[129]	[1]
In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntactico semantic (Peirsman and Pado?, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al, 2011)	[11]	[1]
In the Opinum system we query the M p, M n models with the KenLM (Heafield, 2011) open-source library because it answers the queries very quickly and has a short loading time, which is suitable for a web application	[0]	[1]
In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language	[18, 153]	[1, 1]
In this section, we review relevant details of the Roark (2001) incremental top-down parser, as configured for use here	[402]	[1]
Incremental top-down and left-corner parsing (Roark, 2001a; Roark, 2001b) and head-driven parsing (Charniak, 2001) approaches have directly used generative PCFG models as language models	[0, 102, 400]	[1, 1, 1]
Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units	[73]	[1]
Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)	[11]	[1]
It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)	[14]	[1]
Jiang et al (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging	[1, 0, 130, 9]	[1, 1, 1, 1]
LCFRS (Vijay-Shanker et al, 1987) are a natural extension of CFG in which a single nonterminal node can dominate more than one continuous span of terminals	[74]	[1]
Levy, on the other hand, argued that studies of probabilistic parsing reveal that typically a small number of analyses are assigned the majority of probability mass (Roark, 2001)	[267]	[1]
Linear Context-Free Rewriting Systems Gap-restricted dependency languages are closely related to Linear Context-Free Rewriting Systems (lcfrs) (Vijay-Shanker et al, 1987), a class of formal systems that generalizes several mildly context-sensitive grammar formalisms	[92, 207]	[1, 1]
MT-based projection has been applied to various NLP tasks, such as part of-speech tagging (e.g., Das and Petrov (2011)), mention detection (e.g., Zitouni and Florian (2008)), and sentiment analysis (e.g., Mihalcea et al (2007))	[6, 0, 18, 104]	[1, 1, 1, 1]
Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) extend this approach by weighting individual phrase pairs	[26, 65, 152, 67, 59]	[1, 1, 1, 1, 1]
Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world	[0, 165]	[1, 1]
McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus	[102, 175]	[1, 1]
McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)	[79, 63, 188]	[1, 1, 1]
McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD	[0]	[1]
McDonald et al (2006) use an additional algorithm	[11, 20, 13, 4]	[1, 1, 1, 1]
McDonald et al (2006) use post-processing for non-projective dependencies and for labeling	[11]	[1]
Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint	[0]	[1]
Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees	[34, 95]	[1, 1]
Mimno et al (2009) extend the original concept of LDA to support polylingual topic models (PLTM), both on parallel (such as EuroParl) and partly comparable documents (such as Wikipedia articles)	[35, 29]	[1, 1]
Mimno et al (2009) showed that so long as the proportion of topically-aligned to non-aligned documents exceeded 0.25, the topic distributions (as measured by mean Jensen-Shannon Divergence between distributions) did not degrade significantly	[122]	[1]
Mitchell and Lapata (2008) introduce a whole family of models of compositionality based on vector addition and point wise-multiplication (and a weighted combination of both), evaluated on a sentence similarity task inspired by Kintsch (2001)	[88, 168]	[1, 1]
Mitchell and Lapata (2008) propose a framework to define the composition c= f (a, b, r, K) where r is the relation between a and b, and K is the additional knowledge used to define composition	[57]	[1]
Mitchell and Lapata (2008) propose a framework to represent the meaning of the combination p+ a as a function f operating on four components: c= f (p, a, R, K) (3) R is the relation holding between p and a, and K additional knowledge	[1]	[1]
Mitchell and Lapata (2008) provide a general framework for semantic vector composition: p= f (u, v, R, K) (1) 295 where u and v are the vectors to be composed, R is syntactic context, K is a semantic knowledge base, and p is a resulting composed vector (or tensor)	[189]	[1]
Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing	[49, 190]	[1, 1]
More recently, Liang et al (2011) proposed DCS for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins	[0]	[1]
Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)	[34, 38]	[1, 1]
Multilingual LDA has been used before in natural language processing, e.g. polylingual topic models (Mimno et al, 2009) or multilingual topic models for unaligned text (Boyd-Graber and Blei, 2009)	[29, 0, 35, 6]	[1, 1, 1, 1]
Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing	[20, 109]	[1, 1]
On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi,1985), including, among several others, the tree ad joining grammars (TAGs) of Joshi et al (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases	[27, 24, 74]	[1, 1, 1]
One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Lianget al 2011) or even a binary correct/incorrect signal (Clarke et al2010)	[9, 117]	[1, 1]
Our Wikipedia-based topic similarity feature, w (f, e), is similar in spirit to polylingual topic models (Mimno et al 2009), but it is scalable to full bilingual lexicon induction	[29, 32, 154, 0, 129, 11]	[1, 1, 1, 1, 1, 1]
Our base line is a factored phrase based SMT system that uses the Moses toolkit (Koehn et al, 2007) for translation model training and decoding, GIZA++ (Ochand Ney, 2003) for word alignment, SRILM (Stolcke, 2002) an KenLM (Heafield, 2011) for language modelling and minimum error rate training (Och, 2003) to tune model feature weights	[12]	[1]
Our baseline joint PLSA model (JPLSA) is closely related to the poly-lingual LDA model of (Mimno et al, 2009)	[35]	[1]
Our particular model, LinkLDA, has been applied to a few NLP tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (Yano et al, 2009), modeling topic-aligned articles in different languages (Mimno et al, 2009), and word sense induction (Brody and Lapata, 2009)	[32]	[1]
Our quantization approach follows Federico and Bertoldi (2006) and Heafield (2011) in partitioning the value histogram into 256 equal-sized buckets	[92]	[1]
Our translation system uses cdec (Dyer et al,2010), an implementation of the hierarchical phrase based translation model (Chiang, 2007) that uses the KenLM library (Heafield, 2011) for language model inference	[21]	[1]
Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)	[0]	[1]
Previous joint models mainly focus on word segmentation and POS tagging task, such as the virtual nodes method (Qian et al2010), cascaded linear model (Jiang et al2008a), perceptron (Zhang and Clark, 2008), sub-word based stacked learning (Sun, 2011), re ranking (Jiang et al2008b)	[0]	[1]
Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction	[0, 175]	[1, 1]
Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)	[0]	[1]
Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser	[0]	[1]
Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)	[104]	[1]
Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees	[97]	[1]
Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)	[0]	[1]
Second, their language models were used to rescore n-best speech lists (supplied by Brian Roark, see Roark (2001))	[92]	[1]
Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2	[50]	[1]
Similarly, Polylingual Topic Models (PLTM) (Mimno et al, 2009) generalized LDA to tuples of documents from multiple languages	[35, 0]	[1, 1]
Since the PLTM is not a contribution of this paper, we refer the interested reader to (Mimno et al, 2009) for more details	[9]	[1]
Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features	[18, 113, 0]	[1, 1, 1]
Subramanya et al's model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers	[0, 6, 18, 40]	[1, 1, 1, 1]
Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006)	[58, 4, 104]	[1, 1, 1]
Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al, 2011) of that variable	[84, 42]	[1, 1]
The English German systems were trained on the full 751,088 sentence Europarl corpus and evaluated on the WMT 2006 test set (Koehn and Monz, 2006)	[5]	[1]
The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences	[160, 22]	[1, 1]
The correlations on the document level were computed on the English, French, Spanish and German texts generated by various translation systems in the framework of the first (Koehn and Monz, 2006), second (Callison-Burch et al, 2007) and third shared translation task (Callison-Burchet al, 2008)	[39, 140]	[1, 1]
The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)	[8, 14, 2, 107]	[1, 1, 1, 1]
The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems	[8]	[1]
The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)	[4, 13]	[1, 1]
The language model was compiled into KenLM probing format (Heafield, 2011) and placed in RAM while text phrase tables were forced into the disk cache before each run	[223, 0]	[1, 1]
The method is described in (McCarthy et al, 2004), which we summarise here	[64, 29]	[1, 1]
The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token	[133]	[1]
The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)	[0]	[1]
The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task	[0]	[1]
The parser is an incremental beam-search parser very similar to the sort described in Roark (2001a; 2004), with some changes in the search strategy to accommodate the perceptron feature weights	[268, 223]	[1, 1]
The parser of Charniak (2000) is also a two-stage ctf model, where the first stage is a smoothed Markov grammar (it uses up to three previous constituents as context), and the second stage is a lexicalized Markov grammar with extra annotations about parents and grandparents	[98, 171]	[1, 1]
The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German	[166]	[1]
The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)	[142]	[1]
The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)	[0]	[1]
The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.	[20, 21]	[1, 1]
The syntactic model in (Miller et al, 2000) is similar to Collins', but does not use features like subcat frames and distance measures	[60, 26]	[1, 1]
The three data sets in use in this paper are summarised in Table 1.The translation systems consisted of phrase tables and lexicalised reordering tables estimated using the standard Moses (Koehn et al, 2007) training pipeline, and 5-gram Kneser-Ney smoothed language models estimated using the SRILM toolkit (Stolcke, 2002), with KenLM (Heafield, 2011) used at runtime	[12]	[1]
There are many (structural) mildly context sensitive grammar formalisms ,e.g .mcfg ,lcfrs, mg, and they have been shown to be equivalent (Vijay-Shanker et al., 1987)	[62]	[1]
This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)	[8]	[1]
This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization	[16, 45]	[1, 1]
This configuration is similar to PolyLDA (Mimno et al, 2009) or LinkLDA (Yano et al, 2009), such that utterances from different parties are treated as different languages or blog-post and comments pairs	[32]	[1]
This result is only slightly higher than the highest reported result for this test-set, Bod's (.907) (Bod,2003)	[133, 38, 43]	[1, 1, 1]
Thus given a fragment tf consisting of a sequence of target tokens, we compute LM scores for (i) < s& gt ;tf, (ii )tf and (iii )tf < /s& gt; and use the best score (only) for pruning. While this increases the number of LM queries, we exploit the language model state in formation in KenLM (Heafield, 2011) to optimize the queries by saving the scores for the unchanged states	[0]	[1]
To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation. Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments	[9]	[1]
To put this in perspective, Roark (Roark, 2001) reports oracle results of 0.941 (with the same experimental setup) using his parser to return a variable number of parses	[270]	[1]
To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time	[0]	[1]
Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)	[9, 11]	[1, 1]
We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English	[0]	[1]
We also manually evaluated the RBMT systems and SMT systems in terms of both adequacy and fluency as defined in (Koehn and Monz, 2006)	[123, 130]	[1, 1]
We also use a standard statistical parser (Charniak, 2000) to provide syntactic analysis	[30]	[1]
We analyze some of the cases reported by Koehn and Monz (2006) and Callison-Burch et al (2006)	[140, 39]	[1, 1]
We approximated the most probable parse as follows (following (Bod, 2003))	[70]	[1]
We are further focusing on the shared task of the workshop on Statistical Machine Translation, which took place last year (Koehn and Monz, 2006) and consisted in translating Spanish, German, and French texts from and to English	[6, 8, 5]	[1, 1, 1]
We describe the model for two languages, but it is straightforward to generalize to more than two languages, as in (Mimno et al, 2009)	[30, 166]	[1, 1]
We have proposed a method for unsupervised POS tagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)	[0]	[1]
We modified the Roark (2001) parser to calculate the discussed measures, and the empirical results in ?4 show several things, including: 1) using a fully lexicalized parser to calculate syntactic surprisal and entropy provides higher predictive utility for reading times than these measures calculated via unlexicalized parsing (as in Demberg and Keller); and 2) syntactic entropy is a useful predictor of reading time	[329]	[1]
We present a comparative study on the behavior of several metric representatives from each linguistic level in the context of some of the cases reported by Koehn and Monz (2006) and Callison-Burch et al (2006) (see Section 3)	[39, 140]	[1, 1]
We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph	[49, 37, 51, 50, 36, 41]	[1, 1, 1, 1, 1, 1]
We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters	[3, 18]	[1, 1]
We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)	[188]	[1]
We use the feature templates the same as Jiang et al, (2008) to extract features form E model	[36]	[1]
We use the same method described in (Koehn and Monz, 2006) to perform the significance test	[52, 49]	[1, 1]
We used common tools for phrase-based translation Moses (Koehn et al, 2007) decoder and tools, SRILM (Stolcke, 2002) and KenLM (Heafield, 2011) for language modelling and GIZA++ (Och and Ney, 2000) for word alignments	[12]	[1]
Whereas Miller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance	[0, 26]	[1, 1]
While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)	[0, 16]	[1, 1]
Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available	[15, 3, 154, 10]	[1, 1, 1, 1]
With the help of the respective original authors, the language model implementations by Heafield (2011) and Pauls and Klein (2011) have been integrated with Joshua, dropping support for the slower and more difficult to compile SRILM toolkit (Stolcke, 2002)	[12]	[1]
Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models	[26]	[1]
Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing	[0]	[1]
n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3	[0]	[1]
