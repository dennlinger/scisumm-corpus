query,doc_id,label
"(1993) and Rooth et al (1999) referring to a direct object noun for describing verbs), or used any syn tactic relationship detected by a chunker or a parser (such as Lin (1998) and McCarthy et al (2003)).",[71],[1]
"(Brill, 1995) presents a rule-based part-of-speech tagger for unsupervised training corpus.",[0],[1]
"(Briscoe and Carroll, 1997) observe that in the work of (Brent, 1993), (Manning, 1993) and (Ushioda et al, 1993), the maximum number of distinct subcategorization classes recognized is sixteen, and only Ushioda et al attempt to derive relative subcategorization frequency for individual predicates.","[115, 117, 213]","[1, 1, 1]"
"(Chambers and Jurafsky, 2011) (Poon and Domingos, 2010) (Chen et al 2011) focus on extracting frame-like structures (Baker et al 1998) by defining two types of clusters, event clusters and role clusters.","[11, 103]","[1, 1]"
"(Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al, 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees.","[83, 103]","[1, 1]"
"(Gale et al, 1992) reports that word sense disambiguation would be at least 75% correct if a system assigns the most frequently occurring sense.","[141, 49]","[1, 1]"
"(Kozareva et al, 2008) proposed the use of a doubly-anchored hyponym pattern and a graph to represent the links between hyponym occurrences in these patterns.",[40],[1]
"(Popescu and Etzioni, 2005) and (Qiu et al, 2011) designed syntactic patterns to perform this task.","[20, 60]","[1, 1]"
"(Tetreault and Chodorow, 2008b) challenged the view that using one rater is adequate by showing that preposition usage errors actually do not have high inter-annotator reliability.",[127],[1]
"256 cross-lingual word clusters and the same feature templates as Ta?ckstro?m et al (2012), with the exception that the transition factors are not conditioned on the input. The features used are similar to those used by Turian et al (2010), but include cross-lingual rather than monolingual word clusters.",[64],[1]
"@2009 Association for Computational Linguistics System Combination: In a typical system combi nation task, e.g. Rosti et al.(2007), each compo nent system produces a set of translations, which are then grafted to form a confusion network.",[25],[1]
"A Feature based TAG (FTAG, (Vijay-Shanker and Joshi,1988)) consists of a set of (auxiliary or initial) elementary trees and of two tree composition operations: substitution and adjunction.",[20],[1]
"A benchmark dataset of 27,937 such quadruples was extracted from the Wall Street Journal corpus by Ratnaparkhi et al (1994) and has been the basis of many subsequent studies comparing machine learning algorithms and lexical resources.",[146],[1]
A complete description on WMT-07 evaluation campaign and dataset is available in Callison-Burch et al (2007).,[107],[1]
"A crucial difference from similar approaches, such as SRL with PropBank roles (Pradhan et al, 2004) is that by identifying relations as part of a frame, you have identified a gestalt of relations that enables far more inference, and sentences from the same passage that use other words from the same frame will be easier to link together.",[194],[1]
"A hybrid approach is presented in (Gale and Church, 1993) whose basic hypothesis is that longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sentences.","[18, 4, 90, 115]","[1, 1, 1, 1]"
"A language model is then used to select the most probable realization (Knight and Hatzivassiloglou, 1995).",[109],[1]
"A language model was incorporated using cube pruning (Huang and Chiang, 2007), using a 200 best limit at each node during LM integration.","[189, 133]","[1, 1]"
"A more fine-grained distinction is made by Bean and Riloff (1999) and Vieira and Poesio (2000) to distinguish restrictive from non-restrictive post modification by ommitting those modifiers that occur between commas, which should not be classified as chain starting.",[369],[1]
"A morphological analysis of the Arabic text is then done using the Arabic morphological analyzer and disambiguation tool MADA (Nizar Habash and Roth, 2009), with the MADA-D2 since it seems to be the most efficient scheme for large data (Habash and Sadat, 2006).",[61],[1]
"A principled solution to this problem is to use an SRL system for nominal predicates trained using NomBank (Meyers et al., 2004).","[156, 163]","[1, 1]"
"A recent shared task in biomedical text mining, the BioNLP 09 Shared Task on Event Extraction (Kim et al, 2009), showed that the biomedical natural language processing (BioNLP) community is greatly interested in heading towards the extraction of deep, semantically rich relationships.",[0],[1]
"A similar observation was reported in the parsing literature, where coarse-to-fine inference with multiple passes of roughly equal complexity produces tremendous speed-ups (Petrov and Klein, 2007).","[136, 0]","[1, 1]"
"A straightforward approach to the alignment matrix is to build a log linear model (Liu et al, 2005) for the probability of the alignment A.",[0],[1]
"A synchronous derivation process for the two syntactic structures of both languages suggests the level of cross-lingual isomorphism between the two trees (e.g. Synchronous Tree Adjoining Grammars (Shieber and Schabes, 1990)).",[0],[1]
"A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al,2002) to fine-grained extraction of opinion expressions and their targets (Wu et al, 2009).","[165, 10]","[1, 1]"
"AMaximum Entropy methods (Borthwick et al. 1998, Chieu and Ng 2002)",[46],[1]
"Advanced NLP-based readability metrics developed so far typically deal with English, with a few attempts devoted to other languages, namely French (Collins-Thompson and Callan, 2004), Portuguese (Aluisio et al, 2010) and German (Bruck, 2008).",[111],[1]
"After analyzing the dependency structure of sentences in Penn Chinese Treebank 5.1 (Xue et al, 2002), we found an interesting phenomenon: if we define a main-root as the head of a sentence, and define a subsentence as a sequence of words separated by punctuations, and the head1 of these words is the child of main root or main-root itself, then the punctuations that depend on main-root can be a separator of sub-sentences.","[19, 15]","[1, 1]"
"After obtaining all the extracted noun phrases, we also use a rule-based method to remove some erroneous candidates based on previous studies (e.g. Lee et al (2011), Uryupina et al (2011)).","[36, 6]","[1, 1]"
"Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al, 2011) and a corpus freely available for CLTE is published (Castillo, 2011).",[6],[1]
"Again, according to the work of Carletta et al (1997), a minimum kappa score of 0.67 is required to draw tentative conclusions.",[32],[1]
"Although it can be used in its current form for data-driven Sentiment Analysis (Pang et al., 2002; Pang and Lee, 2004; Kim and Hovy, 2004; Popescu and Etzioni, 2005; Su and Markert, 2009; DanescuNiculescu- Mizil et al., 2009), or for lexical sentiment analysis tasks (Strapparava and Mihalcea, 2007; Su and Markert, 2009), it could also be used as a training set for supervised classifiers that would subsequently be applied for the improvement of Q-WordNet.",[9],[1]
"Although it is beyond the scope of our research, we conjecture that there exists a Monte Carlo disambiguation algorithm for at least Stochastic Tree-Adjoining Grammar (Schabes, 1992).","[0, 204]","[1, 1]"
"Although most generation systems pipeline decisions (Reiter, 1994), we believe the most efficient and flexible way to integrate constraints in sentence planning is to synchronize the decisions.",[32],[1]
Although related to Callison-Burch et al (2006) our method is conceptually simpler and more general.,"[73, 59]","[1, 1]"
"Although see (Goodman 1996) for an efficient algorithm for the DOP model, which we discuss in section 7 of this paper.",[0],[1]
"Although we have not discussed it to this point, (Collins and Roark, 2004) present a perceptron algorithm for use with the Roark architecture.",[173],[1]
"Among these methods, the one using Naive Bayesian Ensemble (i.e., an ensemble of Naive Bayesian Classifiers) is reported to perform the best for word sense disambiguation with respect to a benchmark data set (Pedersen 2000).",[0],[1]
"An existing SCFG parser (Schmid, 2004) was then used, with a simple unknown word heuristic, to generate the Viterbi n-best parses with n= 100, and, after removing the address labels, all equal parses and their probabilities were summed, and the one with highest probability chosen.",[20],[1]
"An obvious first step, which we are currently working on, is to include a linguistically motivated temporal ontology (Moens and Steedman,1988), which will be separate from the existing do main ontology.","[357, 0]","[1, 1]"
"An unsupervised method (Chodorow and Leacock, 2000) is employed to detect grammatical errors by inferring negative evidence from TOEFL administrated by ETS.","[0, 1]","[1, 1]"
"Analogous to our prediction task, Lin and Hsin Yihn (2008) and Socher et al (2011) investigated predicting the emotion of a reader from the text that s/he reads.","[100, 222]","[1, 1]"
"Another advantage of generative models is that they do not suffer from the label bias problems (Bottou, 1991), which is a potential problem for conditional or deterministic history-based models, such as (Nivre et al, 2004).",[148],[1]
"Another difference is that the system in Morante and Daelemans (2009) used shallow syntactic features, whereas this system uses features from both shallow and dependency syntax.",[21],[1]
"Another issue regarding WindowDiff is that it is not clear 'how does one interpret the values produced by the metric' (Pevzner and Hearst, 2002).",[276],[1]
"Another venue of research may be to exploit different thesauri, such as the ones automatically derived as in (Curran and Moens, 2002).",[19],[1]
"Approach Accuracy % Precision % Recall % F-Measure % Fernando et al.(2008) [40] 74.1 75.2 91.3 82.4 Mihalcea et al.(2006) [41] 70.3 69.6 97.7 81.3 Proposed system variant WSD, threshold = 0.2, top 50% 66.4 81.0 65.2 72.3 Cosine similarity, threshold = 0.7 (Wubben et al. [9]) 62.5 80.5 56.6 66.5 k-Means clustering (Wubben et al. [9]) 60.6 70.6 71.0 70.8 FCM clustering 36.2 68.1 9.5 16.7 Table 6 Performance of proposed system on MSRVDC Dataset 1.",[39],[1]
"Approximate parsers have there fore been introduced, based on belief propagation (Smith and Eisner, 2008), dual decomposition (Koo et al, 2010), or multi-commodity flows (Martins et al, 2009, 2011).","[31, 163, 167]","[1, 1, 1]"
"As (Shieber, 1988) showed, the problem with such words is that they can not be selected on the basis of the input semantics.",[298],[1]
"As a Japanese dependency analyzer based on the cascaded chunking model, we use the publicly available version of CaboCha (Kudo and Matsumoto, 2002), which is trained with the manually parsed sentences of Kyoto text corpus (Kurohashi and Nagao, 1998), that are 38,400 sentences selected from the 1995 Mainichi newspaper text.","[81, 85]","[1, 1]"
"As a learning model, we use unigram language modelling introduced in (Collins-Thompson and Callan, 2004) to model the reading level of subjects in primary and secondary school.",[0],[1]
"As a second experiment, we analyze incorrect sense assignments on SemEval-2 Task 14 (Manandhar et al., 2010) to measure whether sense-relatedness biases which sense was incorrectly selected.",[0],[1]
"As an example, among the collected material several translations in languages other than English revealed a massive and defective use of on-line translation tools by untrusted workers, as also observed by (Callison-Burch, 2009).",[125],[1]
"As an illustration of the need to combine grammatical paraphrasing with data-driven paraphrasing, consider the example that Zhao et al (2009) use to illustrate the application of their paraphrasing method to similarity detection, shown in Table 1.","[0, 54, 126]","[1, 1, 1]"
"As another example, Denis and Baldridge (2007) and Finkel and Manning (2008) perform joint inference for anaphoricity determination and coreference resolution, by using Integer Linear Programming (ILP) to enforce the consistency between the output of the anaphoricity classifier and that of the coreference classifier.",[0],[1]
"As described e.g. in Mladova et al. (2009), the annotation framework that we use is based on the knowledge obtained from studying various other systems, especially the Penn Discourse Treebank (Prasad et al., 2008), but naturally it has been adjusted to specific needs of the Czech language and PDT.",[0],[1]
"As shown in the following parts of this paper, it works very well with the existing techniques, such as rule composing (Galley et al, 2006), SPMT models (Marcu et al, 2006) and rule extraction with k best parses (Venugopal et al, 2008).","[11, 197]","[1, 1]"
"As stated above, we aim to build an unsupervised generative model for named entity clustering, since such a model could be integrated with unsupervised coreference models like Haghighi and Klein (2007) for joint inference.",[0],[1]
"As we are not interested in unsupervised inference, the system of Poon and Domingos (2008) was unsuitable for our needs.",[63],[1]
"As with (Taskar et al, 2005b), we use the large-margin structured prediction model.",[40],[1]
"Aside from Florian et al (2004), several authors have also given techniques for adapting classification to new domains.","[22, 9]","[1, 1]"
"Automated evaluation utilizes the standard DUC evaluation metric ROUGE (Lin, 2004) which represents recall over various n-grams statistics from a system generated summary against a set of human generated peer summaries.",[0],[1]
"Axelrod et al (2011) proposed a bilingual cross-entropy difference to select data from parallel corpus for domain adaptation which captures the contextual information slightly, and outperformed monolingual cross-entropy difference (Moore and Lewis, 2010), which first shows the advantage of bilingual data selection.",[94],[1]
B3 here is the B3All version of Stoyanov et al (2009).,"[14, 78, 97]","[1, 1, 1]"
"B5: Lemmatize the tokens using morpha, (Minnen et al, 2000).","[128, 78]","[1, 1]"
"BLEU is smoothed to be more appropriate for sentence level evaluation (Lin and Och, 2004b), and the bi gram versions of BLEU and HWCM are reported because they have higher correlations than when longer n-grams are included.",[142],[1]
"Banea et al (2008) demonstrate that machine translation can perform quite well when extending the subjectivity analysis to multilingual environment, which makes it inspiring to replicate their work on lexicon-based sentiment analysis.","[0, 17]","[1, 1]"
"Bangalore et al.(2001) used a WER based alignment and Sim et al.(2007), Rosti et al.(2007a), and Rosti et al.(2007b) used minimum Translation Error Rate (TER) based alignment to build the confusion network.","[19, 31, 90, 25]","[1, 1, 1, 1]"
"Baroni and Zamparelli (2010) show that their model significantly outperforms other vector composition methods, including addition, multiplication and Guevara's approach, in the task of approximating the correct vectors for previously unseen (but corpus-attested) ANs.",[28],[1]
Barzilay and McKeown (2001) and Callison Burch et al (2006) extracted paraphrases from monolingual parallel corpus where multiple translations were present for the same source.,[0],[1]
"Because such approaches directly learn a generative model over phrase pairs, they are theoretically preferable to the standard heuristics for extracting the phrase pairs from the many-to-one word-level alignments produced by the IBM series models (Brown et al, 1993) or the Hidden Markov Model (HMM) (Vogel et al,1996).","[127, 7]","[1, 1]"
"Beesley and Karttunen (2000) describe a technique, called compile-replace, for constructing FSTs, which involves reapplying the regular-expression compiler to its own output.",[3],[1]
"Besides many works addressing holistic LM domain adaptation for SMT, e.g. Foster and Kuhn (2007), recently methods were also proposed to explicitly adapt the LM to the discourse topic of a talk (Ruiz and Federico, 2011).",[0],[1]
"Besides the increasing availability of an notation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al, 2003b)), the community has also organized three successful evaluation workshops TempEval1 (Verhagen et al, 2009), -2 (Verhagen et al, 2010), and-3 (Uzzaman et al, 2013).","[5, 50]","[1, 1]"
Biemann (2006) described a graph-based clustering methods for word classes.,[53],[1]
Blitzer et al (2007) used structural correspondence learning to train a classifier on source data with new features induced from target unlabeled data.,[171],[1]
"Both Hearst (1994, 1997) and Foltz et al (1998) use vector space methods discussed below to represent and compare units of text.",[164],[1]
"Both Yamada and Knight (2001) and Chiang (2005) use SCFGs as the underlying model, so their translation schemata are syntax-directed as in Fig.",[0],[1]
"Briefly, Clark and Weir (2002) populate the WordNet hierarchy based on corpus frequencies (of all nouns for a verb/slot pair), and then determine the appropriate probability estimate at each node in the hierarchy by using chi square to determine whether to generalize an estimate to a parent node in the hierarchy.",[0],[1]
"By finding semantic differences between the selectional preferences, it can articulate the higher-order structure of conceptual metaphors ((Mason, 2004), p. 24), finding mappings like LIQUID -> MONEY.",[32],[1]
"CL-Web: A state-of-the-art open domain method based on features extracted from the Web documents data set (Pantel et al, 2009).",[41],[1]
Callison-Burch et al (2006) exploited the existence of multiple parallel corpora to learn paraphrases for Phrase-based MT.,"[59, 73]","[1, 1]"
Callison-Burch et al (2006) point out three prominent factors.,"[73, 59]","[1, 1]"
"Callison-Burch et al (2012) report for several automatic metrics on the whole WMT12 English-to-Czech dataset, the best of which correlates at?= 0.18.","[127, 6]","[1, 1]"
Canadian Hansards that has been used in a number of other studies: Church (1993) and Simard et al (1992).,"[1, 62]","[1, 1]"
Cao and Li (2002) propose a new method to translate base noun phrases.,[2],[1]
Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy that had at least twenty descendants.,[71],[1]
Carpuat and Wu (2007) approached the issue as a Word Sense Disambiguation problem.,"[0, 73]","[1, 1]"
Chelba and Jelinek (1998) proposed that syntactic structure could be used as an alternative technique in language modeling.,[0],[1]
Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers.,[201],[1]
"Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002).",[0],[1]
"Co-training has been applied to a number of NLP applications, including POS-tagging (Clark et al, 2003), parsing (Sarkar, 2001), word sense disambiguation (Mihalcea, 2004), and base noun phrase detection (Pierce and Cardie, 2001).","[145, 7]","[1, 1]"
Collins (1996) proposed a statistical parser which is based on probabilities of dependencies between head-words in the parse tree.,"[0, 1]","[1, 1]"
"Collins and Duffy (Collins and Duffy, 2002) suggested to employ convolution kernels to measure similarity between two trees in terms of their sub structures, and more recently, Moschitti (Moschitti, 2006) described in details a fast implementation of tree kernels.",[125],[1]
Collins and Roark (2004) and Taskar et al (2004) beat the generative baseline only after using the standard trick of using the output from a generative model as a feature.,[11],[1]
"Commonly, MTurk has been used for the classification task (Snow et al. 2008) or for straightforward data entry.",[8],[1]
"Compared to the over feature size of 200000 in Li and Roth (2002), our feature space is much more compact, yet turned out to be more informative as suggested by the experiments.",[105],[1]
"Compared with the disappointing results of joint learning on syntactic and semantic parsing, Miller et al (2000) and Finkel and Manning (2009) showed the effectiveness of joint learning on syntactic parsing and some simple NLP tasks, such as information extraction and name entity recognition.",[0],[1]
"Compared with the previous work on katakana to-English transliteration, these accuracies do not look particularly high: both Knight and Graehl (1998) and Bilac and Tanaka (2004) report accuracies above 60% for 1-best transliteration.","[0, 17]","[1, 1]"
"Comparing the latter half of the experimental results with those on parsing (Miyao and Tsujii, 2005), we investigated similarities and differences between probabilistic models for parsing and generation.",[0],[1]
Corpus creation using AMT has numerous precedents now; see i.e. Callison-Burch and Dredze (2010) and Heilman and Smith (2010b).,"[200, 163]","[1, 1]"
"Currently supervised methods achieve the best disambiguation quality (about 80% precision and recall for coarse-grained WSD in the most recent WSD evaluation conference SemEval 2007 (Navigli et al, 2007)).",[101],[1]
"D-Tree Grammar (DTG) is proposed in (Rambow et al, 1995) to remedy some empirical and theoretical shortcomings of TAG; Tree Description Grammar (TDG) is introduce din (Kallmeyer, 1999) to support syntactic and semantic underspecification and Interaction Grammar is presented in (Perrier, 2000) as an alternative way of formulating linear logic grammars.","[75, 0]","[1, 1]"
"Decision tree algorithms were used for reference resolution by Aone and Bennett (1995, C4.5), McCarthy and Lehnert (1995, C4.5) and Soon et al (2001, C5.0).","[306, 307]","[1, 1]"
"Despite some recent advances in this direction (Bos et al, 2004), it is still the case that it is hard to obtain deep semantic analyses which are accurate enough to support logical inference (Lev et al, 2004).","[14, 18]","[1, 1]"
"Ding and Palmer (2005) propose a syntax-based translation model based on a probabilistic synchronous dependency insert grammar, a version of synchronous grammars defined on dependency trees.","[46, 3, 0]","[1, 1, 1]"
Distances have been used in e.g. Luo et al (2004).,"[146, 9]","[1, 1]"
"Due to space constraints, details and proof of correctness are available in Lopez (2007a).",[164],[1]
"EM-based clustering, originally introduced for the induction of a semantically annotated lexicon (Rooth et al, 1999), regards classes as hidden variables in the context of maximum likelihood estimation from incomplete data via the expectation maximisation algorithm.",[17],[1]
"Early unsupervised approaches to the SRL task include (Swier and Stevenson, 2004), where theVerbNet verb lexicon was used to guide unsupervised learning, and a generative model of Grenager and Manning (2006) which exploits linguistic priors on syntactic-semantic interface.",[0],[1]
"Early works reward/penalize spans that respect the syntactic parse constituents of an input sentence (Chiang, 2005), and (Marton and Resnik, 2008).",[10],[1]
"Echihabi and Marcu (2003) have developed a noisy-channel model for QA, which explains how a sentence containing an answer to a given question can be rewritten into that question through a sequence of stochastic operations.","[0, 22]","[1, 1]"
"Efficiently storing such structures is an important step in integrating document-level statistics into downstream tasks, such as characterizing complex scenarios (Chambers and Jurafsky, 2011), or story understanding (Gordon et al, 2011).",[103],[1]
"Eisner (1996, section 5) also provides a safe and complete parsing algorithm which can return non-NF derivations when necessary to preseve an interpretation if composition is bounded or the grammar is restricted in other (arbitrary) ways.",[151],[1]
Eisner (2002) gives a general EM algorithm for parameter estimation in probabilistic finite-state transducers.,[0],[1]
"English to French Lexical-Structural Transfer Rule with Verb Modifier ALMOST More details on how the structural divergences described in (Dorr, 1994) can be accounted for using our formalism can be found in (Nasr et al., 1998).",[45],[1]
"Evaluation campaigns like WMT (Callison-Burch et al, 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks.","[5, 147]","[1, 1]"
"Evaluation is performed on several datasets of tweets that have been annotated for polarity: the Stanford Twitter Sentiment set (Go et al, 2009), Davidov et al (2010) use 15 emoticons and 50 Twitter hash tags as proxies for sentiment in a similar manner, but their evaluation is indirect.","[35, 85]","[1, 1]"
"Except for the addition of a tag parameter p to the SHIFT transition, this is equivalent to the system described in Nivre (2009), which thanks to the SWAP transition can handle arbitrary non-projective trees.",[120],[1]
"Experiments are performed using all train/test pairs among three conversational speech corpora: the Meeting Recorder Dialog Actcorpus (MRDA) (Shriberg et al, 2004), Switch board DAMSL (Swbd) (Jurafsky et al, 1997), and the Spanish Callhome dialog act corpus (SpCH) (Levin et al, 1998).",[0],[1]
"Feature function scaling factors m are optimized based on a maximum likelihood approach (Och and Ney, 2002) or on a direct error minimization approach (Och, 2003).",[89],[1]
"Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture.","[36, 152]","[1, 1]"
Filatova and Hovy (2001) infer time values based on the most recently assigned date or the date of the article.,"[102, 68, 71, 97, 94, 100]","[1, 1, 1, 1, 1, 1]"
"Finally, all texts were lemmatized using Porter's stemmer (1980) for English and Snowballstemmers for other languages using an implementation provided by the NLTK (Loper and Bird, 2002).",[106],[1]
"Finally, results are presented from the SemEval-2007 coarse grained all-words task (Navigli et al, 2007), and we explore the influence of various types of selectors on the algorithm in order to draw insight for future improvement of Web-based methods.","[0, 1]","[1, 1]"
Finkel et al (2005) used simulated annealing with Gibbs sampling to find a solution in a similar situation.,[129],[1]
"First, we adopt an ONTOLOGICALLY PROMISCUOUS representation (Hobbs, 1985) that includes a wide variety of types of entities.",[0],[1]
"First, we can let the number of nonterminals grow unboundedly, as in the Infinite PCFG, where the nonterminals of the grammar can be indefinitely refined versions of a base PCFG (Liang et al, 2007).",[232],[1]
"First, we investigate the impact of using different flavours of Covington's algorithm (Covington, 2001) for non projective dependency parsing on the ten different languages provided for CoNLL-X Shared Task (Nivre et al, 2007).",[0],[1]
"Following (Yao et al, 2011), we filter out noisy documents and use natural language packages to annotate the documents, including NER tagging (Finkel et al, 2005) and dependency parsing (Nivre et al, 2004).","[129, 47]","[1, 1]"
"Following Barzilay and Lee (2003), we approach the sentence clustering task by hierarchical complete-link clustering with a similarity metric based on word n-gram overlap (n= 1, 2, 3).",[68],[1]
"Following Galley et al (2006)' s work, Marcu et al (2006) proposed SPMT models to improve the coverage of phrasal rules, and demonstrated that the system performance could be further improved by using their proposed models.","[127, 45]","[1, 1]"
"Following Hale (2001) and Levy (2008), among others, the syntactic processor uses an incremental probabilistic Earley parser to compute a metric which correlates with increased reading difficulty.",[0],[1]
"Following Nivre (2008), we define a transition system for dependency parsing as a quadruple S= (C, T, cs, Ct), where 1. C is a set of configurations, 2. T is a set of transitions, each of which is a (partial) function t : C → C, 3. cs is an initialization function, mapping a sentence x to a configuration c ∈ C, 4. Ct ⊆ C is a set of terminal configurations.","[95, 88]","[1, 1]"
"Following Reisinger and Mooney (2010), we also evaluated mixture models that combine the output of models with varying parameter settings.",[0],[1]
"Following Shen et al (2008), we distinguish between fixed, floating, and ill-formed structures.","[84, 114]","[1, 1]"
"Following Turian et al (2010), we use Percy Liang's implementation of this algorithm for our comparison, and we test runs with 100, 320, and 1000 clusters.",[163],[1]
"Following models were applied: n-gram posteriors (Zens and Ney, 2006b), sentence length model, a 6-gram LM and single word lexicon models in both normal and inverse direction.",[43],[1]
"Following phrase-based methods in statistical machine translation (Koehn et al., 2003).",[0],[1]
"Following previous work (e.g., Soon et al (2001) and Ponzetto and Strube (2006)), we generate training instances as follows: a positive instance is created for each anaphoric NP, NPj, and its closest antecedent, NPi; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+1, NPi+2,..., NPj-1.",[50],[1]
"Following studies on automatic SCF extraction (Brent, 1993), we apply a statistical test (Binomial Hypothesis Test) to the unfiltered-Levin-SCF to filter out noisy SCFs, and denote the resulting SCF set as filtered-Levin SCF.",[152],[1]
"For English texts, these trees were first provided by the Connexor parser at UMIACS (Tapanainen and Jarvinen, 1997), and then corrected by one of the team PIs.",[142],[1]
"For German, we obtain a tagging accuracy of 97.24, which is close to the 97.39 achieved by the RFTagger (Schmid and Laws, 2008), which to our knowledge is the best tagger for German",[166],[1]
"For SemEval 2007, all systems performed better than the random base line of 53.43%, but only 4 of 13 systems achieved an F1 score higher than the MFS baseline of 78.89% (Navigli et al, 2007). Table 2 lists the results of applying the generalized Web selector algorithm described in this paper in a straight-forward manner, such that all scale (T) are set to 1.","[60, 63]","[1, 1]"
"For a given set of questions, the task here is to rank candidate answers (Wang et al, 2007).",[184],[1]
"For an alignment model, most of these use the Aachen HMM approach (Vogel et al, 1996), the implementation of IBM Model 4 in GIZA++ (Och and Ney, 2000) or, more recently, the semi-supervised EMD algorithm (Fraser and Marcu, 2006).",[27],[1]
"For dependency parsing, McDonald and Pereira (2006) proposed a method which can incorporate some types of global features, and Riedel and Clarke (2006) studied a method using integer linear programming which can incorporate global linguistic constraints.",[0],[1]
"For each pair of entity mentions, we extract and compute various lexical and syntactic features, as employed in a state-of-the-art relation extraction system (Zhou et al., 2005).",[60],[1]
"For each system, we report the performance of max-derivation decoding (MAX), hyper graph-based MBR (Kumar et al, 2009), and a linear version of forest-based consensus decoding (CON) (DeNero et al., 2009).",[179],[1]
"For example transducer determinization (Mohri, 1997) uses a set of pairs of states and weights.",[240],[1]
"For example, CCGbank (Hockenmaier and Steedman, 2007) contains 1241 distinct supertags (lexical categories) and the most ambiguous word has 126 supertags.",[399],[1]
"For example, Chiang et al. [3] designed many target-side syntax features to improve the string-to-tree translation.",[51],[1]
"For example, Chklovski and Pantel (2004) loosely define ENABLEMENT as a relation that holds between two verbs V1 and V2 when the pair can be glossed as V1 is accomplished by V2 and gives two examples: assess: :review and accomplish: :complete.","[87, 85]","[1, 1]"
"For example, Ng et al (2003) acquired sense examples using English-Chinese parallel corpora, which were manually or automatically aligned at sentence level and then word-aligned using software.","[147, 38]","[1, 1]"
"For example, Petrov et al (2012) build supervised POS taggers for 22 languages using the TNT tagger (Brants, 2000), with an average accuracy of 95.2%.",[24],[1]
"For example, Wu et al (2009) identified aspects based on the features explored by dependency parser.","[165, 10]","[1, 1]"
"For example, Zettlemoyer and Collins (2007) used a predicate from (f, c) to signify that flight f starts from city c.",[69],[1]
"For example, an SVM-based NE-chunker run sat a rate of only 85byte/sec, while previous rule based system can process several kilobytes per second (Isozaki and Kazawa, 2002).","[13, 117]","[1, 1]"
"For example, detecting subjective sentences, expressions, and other opinionated items in documents representing certain press categories (Wiebe et al, 2004) and measuring strength of subjective clauses (Wilson et al, 2004).",[455],[1]
"For example, the features introduced by Chiang et al (2008) and Chiang et al (2009) for an SCFG model for Chinese/English translation are of two types: The first type explicitly counters overestimates of rule counts, or rules with bad overlap points, bad rewrites, or with undesired insertions of target-side terminals.",[14],[1]
"For examples of work in producing abstract-like summaries, see Radev and McKeown (1998), which combines work in information extraction and natural language processing.",[0],[1]
"For further details see e.g. (Tillmann and Ney, 2003).",[290],[1]
"For instance, (Cohn and Lapata, 2007) explore the use of triangulation for machine translation, where multiple translation models are learned using multilingual parallel corpora.",[0],[1]
"For instance, Gildea and Hockenmaier (2003) reported that a CCG-based parser gives improved results over the Collins parser.",[8],[1]
"For instance, to produce sentence alignments, Brown et al (1991) and Gale and Church (1991) both proposed methods that completely ignored the lexical content of the texts and both reported accuracy levels exceeding 98%.","[18, 19]","[1, 1]"
"For selecting the best skeleton, two common methods are choosing the hypothesis with the Minimum Bayes Risk with translation error rate (TER) (Snover et al, 2006) (i.e., the hypothesis with the minimum TER score when it is used as the reference against the other hypotheses) (Sim et al, 2007) or choosing the best hypotheses from each system and using each of those as a skeleton in multiple confusion networks (Rosti et al, 2007b).","[25, 105, 116, 38]","[1, 1, 1, 1]"
"For the Brown algorithm, we are contrasting cluster count choices of 320 and 1000, based on reports of other successful applications [Turian et al, 2010], with clustering models trained on monolingual data from the Europarl corpus and the News Commentary corpus.",[59],[1]
"For the alignment of supplemental data with candidate outputs, we apply M2M ALIGNER (Jiampojamarn et al, 2007).",[21],[1]
"For the discourse structure analysis, we suggest a statistical model with discourse segment boundaries (DSBs) similar to the idea of gaps suggested for a statistical parsing (Collins (1996)).",[0],[1]
For the experimental evaluations we use the Bidirectional Tagger with Guided Learning presented in Shen et al (2007).,[0],[1]
"For the past decade, MT evaluation has relied heavily on inexpensive automatic metrics such as BLEU (Papineni et al, 2002), NIST (Doddington, 2002), METEOR (Banerjee and Lavie, 2005), PER (Tillmann et al, 1997), CDER (Leusch et al, 2006), WER (Nie?en et al, 2000), and TER (Snover et al, 2006).","[170, 71]","[1, 1]"
"For the predicate identification, we used the features suggested by Johansson and Nugues (2008).","[79, 88]","[1, 1]"
"For the second kind, Niessen and Ney (2004) used morpho-syntactic information for translation between language pairs with scarce resources.","[0, 244]","[1, 1]"
"For these features we replace the opinion words with their positive or negative polarity equivalents (Lin et al, 2006).","[30, 33]","[1, 1]"
"For this purpose, existing work on coreference resolution (Lee et al, 2011) may prove to be useful.",[6],[1]
"For this we adopt the approach of Blunsom et al (2009b), who present a method for maintaining table counts without needing to record the table assignments for each translation decision.",[22],[1]
"For translation experiments, we used cdec (Dyer et al, 2010), a fast implementation of hierarchical phrase-based translation models (Chiang, 2005), which represents a state-of-the-art translation system.",[6],[1]
"Fortunately, exploiting the recursive nature of the cells, we can compute values for the inside and outside components of each cell using dynamic programming in O (n4) time (Zhang and Gildea, 2005).",[65],[1]
"From machine learning perspective, both proposed methods can be viewed as certain form of transductive learning applied to the SMT task (Ueffing et al, 2007).","[0, 157]","[1, 1]"
"Fung and Cheung (2004a) describe corpora ranging from noisy parallel, to comparable, and finally to very non-parallel.","[33, 153]","[1, 1]"
"Furthermore, we plan to include the Level 1 translations into the candidate answer generation module in order to do query expansion in the style of Riezler et al (2007).","[33, 8]","[1, 1]"
"GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al, 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007).",[197],[1]
Gamon et al (2008) and Gamon (2010) use a combination of classification and language modeling.,"[44, 51]","[1, 1]"
"Generative Lexicon (Pustejovsky, 1991), for example have been proposed to facilitate computationally precise description of natural language syntax and semantics.","[0, 391]","[1, 1]"
"Generative models are also used in unsupervised coreference (Haghighi and Klein, 2010).","[12, 13]","[1, 1]"
"Germann et al (2001) suggested greedy method and integer programming decoding, though the first method suffer from the similar problem as described above and the second is impractical for the real-world application.",[90],[1]
Gibbs sampling updates for LDAWN are given in Boyd-Graber et al (2007).,[14],[1]
"Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al, 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al, 2007), and concept lists (Katz et al, 2003).",[8],[1]
"Goldwater et al (2006) introduced two nonparametric Bayesian models of word segmentation, which are discussed in more detail in (Goldwater et al, 2009).","[142, 74]","[1, 1]"
Graehl and Knight (2004) proposed the use of target tree-to-source-string transducers (xRs) to model translation.,[113],[1]
Hasegawa et al (2004)'s method is to use a hierarchical clustering method to cluster pairs of named entities according to the similarity of context words intervening between the named entities.,"[4, 190]","[1, 1]"
"Hierarchical Phrase-based Machine Translation, proposed by Chiang (Chiang, 2007), uses a general non-terminal label X but does not use linguistic information from the source or the target language.",[0],[1]
"Hindle (1990) uses a mutual-information based metric derived from the distribution of subject, verb and object in a large corpus to classify nouns.",[1],[1]
Hockenmaier and Steedman (2002) describe a generative model of normal-form derivations.,"[31, 22]","[1, 1]"
"However, Zhang et al (2008b) and Sunet al (2009) demonstrate that the additional expressivity gained from non-contiguous rules greatly improves the translation quality.","[110, 30]","[1, 1]"
"However, several techniques for mining name transliterations from monolingual and comparable corpora have been studied (Pasternack and Roth, 2009), (Goldwasser and Roth, 2008), (Klementiev and Roth, 2006), (Sproat et al, 2006), (Udupa et al, 2009b).",[57],[1]
"However, this method does not work for realworld datasets such as PASCAL RTE (Dagan et al., 2006), because of the knowledge bottleneck: it is often the case that the lack of sufficient linguistic knowledge causes failure of inference, thus the system outputs ""no entailment"" for almost all pairs (Bos and Markert, 2005).","[191, 139]","[1, 1]"
"However, we attempted to run an experiment as similar as possible in setup to Koehn and Knight (2002), using English Gigaword and German Europarl.","[97, 170]","[1, 1]"
"However, we can learn to attribute some similarity between (Brown et al, 1990) and the second publication using the text in (Marcu and Wong, 2002).",[112],[1]
"If it is extended to labeled parsing (a straightforward extension), our formulation fully subsumes that of Riedel and Clarke (2006), since it allows using the same hard constraints and features while keeping the ILP polynomial in size.",[57],[1]
"Iglesias et al. (2009) show that exact FST decoding is feasible for a phrase-based system with limited reordering (the MJ1 model (Kumar and Byrne, 2005)), and de Gispert et al (2010) show that exact FST decoding is feasible for a specific class of hierarchical grammars (shallow-1 grammars).","[9, 23]","[1, 1]"
"Importantly, Hindle's system allows for non surface-based corrections and sequential application of correction rules (Hindle, 1983, p. 123).",[131],[1]
"In (Brown et al, 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al, 1993) with an ASR system.","[578, 567, 23]","[1, 1, 1]"
"In (Knight,1999) it was proved that the Exact Decoding problem is NP-Hard when the language model is a bigram model.",[0],[1]
"In ACE04 and ACE05, we have only the newswire portion (of the original ACE 2004 and 2005 training sets) and use the standard train/test splits reported in Stoyanov et al (2009) and Haghighi and Klein (2010).",[142],[1]
"In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al, 2001), PropBank (Palmer et al, 2005) and NomBank (Meyers et al, 2004) have been created and utilized.","[156, 163, 8]","[1, 1, 1]"
In Hulth (2003a) an evaluation of three different methods to extract candidate terms from documents is presented.,[132],[1]
"In NLP, label propagation has been used for word sense disambiguation (Niu et al, 2005), document classification (Zhu, 2005), sentiment analysis (Goldberg and Zhu, 2006), and relation extraction (Chen et al, 2006).","[8, 52]","[1, 1]"
"In Velikovich et al (2010), the parameters were tuned on a held out dataset.","[46, 124]","[1, 1]"
"In a second experiment, we applied the feature discovery procedure to the English corpus from CoNLL 2008 (Surdeanu et al, 2008), a dependency corpus converted from the Penn Tree bank and the Brown corpus.",[109],[1]
"In addition, the work of Kahane et al (1998) provides a polynomial parsing algorithm for a constrained class of non projective structures.",[0],[1]
"In all cases, the final log-linear models were optimized on the dev set using lattice-based Minimum Error Rate Training (Macherey et al, 2008).",[0],[1]
"In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002).",[0],[1]
"In contrast, (Barbosa and Feng, 2010) propose a two-step approach to classify the sentiments of tweets using SVM classifiers with abstract features.","[46, 152]","[1, 1]"
"In example 1, the context requires a definite article, and the definite article, in turn, calls for the 4Our error classification was inspired by the classification developed for the annotation of preposition errors (Tetreault and Chodorow, 2008a).","[120, 133]","[1, 1]"
"In fact, the Stanford coreference resolver (Lee et al 2011), which won the CoNLL-2011 shared task on coreference resolution, adopts the once-popular rule-based approach, resolving pronouns simply with rules that encode the aforementioned traditional linguistic constraints on coreference, such as the Binding constraints and gender and number agreement. The infrequency of occurrences of difficult pronouns in these standard evaluation corpora by no means undermines their significance, however.",[6],[1]
In future work we will compare our semantics construction principles to the general model of Copestake et al (2001).,"[12, 0]","[1, 1]"
"In general, machine learning based methods to relation extraction perform very well for any task where sufficient, representative and high quality training data is available (Kazama et al., 2002).","[15, 12]","[1, 1]"
"In order to produce the gold standard annotations in GerManC-GS we used the GATE platform, which facilitates automatic as well as manual annotation (Cunningham et al 2002).",[227],[1]
"In our corpus study (Poesio and Vieira, 1998) we found that our subjects did better at ideutifying discourse-new descriptions all together.",[91],[1]
"In our experiments we use the clusters obtained in (Koo et al, 2008), but were unable to match the accuracy reported there, perhaps due to additional features used in their implementation not described in the paper.",[32],[1]
"In our experiments, we used the same settings as (Kudo and Matsumoto, 2002).","[80, 87, 97]","[1, 1, 1]"
"In our implementation we approach these tasks in a two-step approach as proposed in (Gamon et al, 2008).",[24],[1]
"In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005).",[0],[1]
"In our opinion, the non-contiguous phrasal rules themselves may not play a trivial role, as reported in Zhang et al (2008a).","[20, 110]","[1, 1]"
"In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al, 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012).","[99, 198]","[1, 1]"
"In particular, the first alignment model we will present has already been described in (Melamed, 2000).",[122],[1]
"In recent years, Akkaya et al (2009) report a successful empirical result where WSD helps improving sentiment analysis, while Wiebe and Mihalcea (2006) study the distinction between objectivity and subjectivity in each different sense of a word, and their empirical effects in the context of sentiment analysis.",[22],[1]
"In recent years, NomBank (Meyers et al,2004a) has provided a set of about 200,000 manually annotated instances of nominalizations with arguments, giving rise to supervised machine learned approaches such as (Pradhan et al, 2004) and (Liu and Ng, 2007), which perform fairly wellin the overall task of classifying deverbal arguments.",[163],[1]
"In the CoNLL-2000 shared task, we achieved the accuracy of 93.48 using IOB2-F representation (Kudo and Matsumoto, 2000b).",[142],[1]
"In the context of automated preposition and determiner error correction in L2 English, De Felice and Pulman (2008) noted that the process is often disrupted by misspellings.","[0, 9]","[1, 1]"
"In the current BioNLP 11 Shared Task1 (Kim et al, 2011), we demonstrate its generalizability to different event extraction tasks by applying what is, to a large extent, the same system to every single task and subtask.","[0, 3]","[1, 1]"
"In the discriminative reranking method (Collins and Koo, 2005), first, a set of candidates is generated using a base model (GEN).",[0],[1]
"In the end I decided to require the students to learn python because I wanted to use NLTK, the Natural Language Toolkit (Loper and Bird, 2002).",[0],[1]
"In the system by Vieira and Poesio (2000), for example, WordNet is consulted to obtain the synonymy, hypernymy and meronymy relations for resolving the definite anaphora.",[536],[1]
"In these experiments we have used a variant of Dice, proposed by Curran and Moens (2002).",[19],[1]
"In these tables, we report the F-measure of identifying the precise location of a story boundary as well as three metrics designed specifically for this type of segmentation task: the pk metric (Beeferman et al, 1999), WindowDiff (Pevzner and Hearst, 2002) and Cseg (Pseg= 0.3) (Doddington, 1998).","[58, 59]","[1, 1]"
"In this bakeoff, our basic model is based on the framework described in the work of Ratnaparkhi (1996) which was applied for English POS tagging.",[47],[1]
"In this paper, we adopt the B3all variation proposed by Stoyanov et al (2009), which retains all twin less markables.",[14],[1]
"In this paper, we describe 1) a new dependency conversion (Section 3) of the Penn Treebank (Marcus, et al, 1993) along with the associated dependency label scheme, which is based upon the Stanford parser's popular scheme (de Marneffe and Manning, 2008), and a fast, accurate dependency parser with non-projectivity support (Section 4) and additional integrated semantic annotation modules for automatic preposition sense disambiguation and noun compound interpretation (Section 5).","[12, 25]","[1, 1]"
"In this paper, we focus on phrase structure parsing with function labelling as a post-processing step. Integer linear programs have already been successfully used in related fields including semantic role labelling (Punyakanok et al, 2004), relation and entity classification (Roth and Yih, 2004), sentence compression (Clarke and Lapata, 2008) and dependency parsing (Martins et al, 2009).",[9],[1]
"In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al (2001) and presented improvements that drastically reduce the decoder's complexity and speed to practically linear time.",[90],[1]
"In this paper, we obtain syntactic clusters from the Berkeley parser (Petrov et al., 2006).","[121, 112]","[1, 1]"
"In this section, we make a comparison of several different TAG parsing algorithms - the CYK based algorithm described at (Vijay-Shanker and Joshi, 1985), Earley-based algorithms with (Alonso et al, 1999) and without (Schabes, 1994) the valid prefix property (VPP), and Nederhof's algorithm (Nederhof, 1999) - on the XTAG English grammar (release 2.24.2001), by using our system and the ideas we have explained.",[268],[1]
"In this work, we focus on Twitter because the labeled corpus by Gimpel et al (2011) allows us to quantitatively evaluate our approach.",[5],[1]
Incremental refers to the results reported in Seginer (2007).,[0],[1]
"It also provides a mapping from the FrameNet deep semantic roles to general thematic roles (list defined in (Moldovan et al 2004)), and use cases for VerbNet.","[1, 153]","[1, 1]"
"It has often been proposed that children might make use of information about the contextual distribution of usage of words to induce the parts-of-speech of their native language (e.g. Maratsos and Chalkley, 1980), and work by, e.g., Redington, Chater and Finch (1998) and Clark (2000), showed that parts-of-speech can indeed be induced by clustering together words that are used in similar contexts in a corpus.",[67],[1]
"It has shown promise in improving the performance of many tasks such as name tagging (Miller et al, 2004), semantic class extraction (Lin et al, 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004) and text classification (Blum and Mitchell, 1998).",[115],[1]
It is a slight variation of the proof given by Rush et al (2010).,[122],[1]
"It is interesting to compare our approach with techniques for well-nested dependency trees (Kuhlmann and Nivre, 2006).",[68],[1]
"It is only recently employed in NER (Shen et al, 2004).","[9, 30]","[1, 1]"
"It is possible to prove that, provided the training set (xi ,zi) is separable with margin > 0, the algorithm is assured to converge after a finite number of iterations to a model with zero training errors (Collins and Roark, 2004).",[53],[1]
"It might be used to rapidly compute approximate outside-probability estimates to prioritize best-first search (e.g., Caraballo and Charniak, 1998).",[104],[1]
"Jing and McKeown (2000) manually analyzed 30 human-written summaries, and find that 19% of sentences can not be explained by cut-and-paste operations from the source text.",[31],[1]
"KAON Text-To-Onto (Maedche and Staab, 2004) applies text mining algorithms for English and German texts to semi-automatically create an ontology, which includes algorithms for term extraction, for concept association extraction and for ontology pruning. Pattern-based approaches to extract hy ponym/hypernym relationships range from hand-crafted lexico-syntactic patterns (Hearst, 1992) to the automatic discovery of such patterns by e.g. a minimal edit distance algorithm (Pantel et al, 2004).",[26],[1]
"Karlgren and Cutting (1994) use a combination of structural markers (e.g., noun count), lexical markers (e.g., it count), and token-level markers (e.g., words per sentence average ,type/token ratio, etc.).",[5],[1]
Kay and Roscheisen (1993) tried lexical methods for sentence alignment.,[147],[1]
"Kim and Hovy (2006) and Bethard et al (2005) explore the usefulness of semantic roles provided by FrameNet (Fillmore et al, 2003) for both opinion holder and opinion target extraction.","[37, 39]","[1, 1]"
Kim and Hovy (2006) proposed to map the semantic frames of FrameNet into opinion holder and target for only adjectives and verbs.,[73],[1]
"Kudo and Matsumoto (2002) give more comprehensive comparison with the probabilistic models as used in (Uchimoto et al, 1999).","[83, 7]","[1, 1]"
"Kumar and Byrne (2005) define two local reordering models for their Translation Template Model (TTM): In the first one, called MJ-1, only adjacent phrases are allowed to swap, and the movement has to be done within a window of 2.",[9],[1]
"Kupiec proposes an Mgorithm for finding noun phrases in bilingual corpora (Kupiec, 1993).",[0],[1]
"LSA Match: v and M (v) are distributionally similar according to a freely available Latent Semantic Indexing package,2 or for verbs similar according to VerbOcean (Chklovski and Pantel, 2004).","[66, 0]","[1, 1]"
"Last, we include all the nouns and verbs used in the SemEval 2010 WSI Task (Manandhar et al, 2010), which are used in our evaluation.","[44, 32]","[1, 1]"
"Less general approaches based on matching have been proposed in (Matusov et al, 2004) and (Taskar et al., 2005).",[40],[1]
Li and Abe (1998) model selectional preferences of a verb (for an argument position) as a set of nodes in the semantic class hierarchy with a probability distribution over them.,[281],[1]
"Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations.",[65],[1]
"Like Toutanova and Moore (2002), we use the n-gram LTP model from Fisher (1999) to predict these pronunciations.",[77],[1]
Lin (1999) assumes that a target expression is non-compositional if and only if its (I) J+ value is significantly different from that of any of the variants.,[48],[1]
Liu et al (2005) used a conditional log-linear model with similar features to those we have employed.,[0],[1]
"MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al, 2009) and translation models (Chiang et al, 2008).","[35, 79, 8, 38]","[1, 1, 1, 1]"
"MULTIR uses features which are based on Mintz et al (2009) and consist of conjunctions of named entity tags, syntactic dependency paths between arguments, and lexical information.","[79, 100]","[1, 1]"
"Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al, 2002).",[97],[1]
"Many corpus based methods have been proposed to deal with the sense disambiguation problem when given definition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, e.g., supervised sense disambiguation (Leacocketal., 1998), and semi-supervised sense disambiguation (Yarowsky, 1995).",[133],[1]
"Many discourse segmentation techniques (e.g. Hirschberg and Litman, 1993) as well as some topic segmentation algorithms rely on cue words and phrases.",[400],[1]
"Many evaluation metrics have been proposed in the past two decades, including the MUC measure (Vilain et al, 1995), B-cubed (Bagga and Baldwin, 1998), CEAF (Luo, 2005) and, more recently, BLANC gold (Recasens and Hovy, 2011).",[20],[1]
"Many of the possible cooccurrences are not observed even in a very large corpus (Church and Mercer, 1993).",[322],[1]
"Many researchers have attempted to make use of cue phrases (Hirschberg and Litman, 1993).","[260, 400]","[1, 1]"
Marcu and Wong (2002) proposed a phrase-based alignment model which suffered from a massive parameter space and intractable inference using expectation maximisation.,[0],[1]
Mark Lauer (1995) only considered English noun compounds and applied a different disambiguation strategy based on word association scores.,[37],[1]
"Maximum entropy classification (MaxEnt) is a technique which has proven effective in a number of natural language processing applications (Berger et al, 1996).",[0],[1]
"Meanwhile, we also use a word-level combination framework (Rosti et al, 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result.",[21],[1]
Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data.,[0],[1]
Melamed (1999) normalized LCS by dividing the length of the longest common subsequence by the length of the longer string and called it longest common subsequence ratio (LCSR).,[147],[1]
Melamed (2003) discussed the applicability of the so-called hook trick for parsing bilexical multi text grammars.,[0],[1]
"Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al, 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b).",[168],[1]
"Messages are partitioned into multi-paragraph segments using TextTiling, which reportedly has an overall precision of 83% and recall of 78% (Hearst, 1994).","[0, 145, 19]","[1, 1, 1]"
"Mihalcea et al, (2007) and Banea et al, (2008) used machine translation technique to leverage English resources for analysis in Romanian and Spanish languages.","[95, 76]","[1, 1]"
"Mikheev (1997) suggested a guessing-rule technique, based on prefix morphological rules ,suffix morphological rules, and ending-guessing rules.","[263, 9, 4, 51]","[1, 1, 1, 1]"
"Minimum Bayes Risk (MBR) techniques have been successfully applied to a wide range of natural language processing tasks, such as statistical machine translation (Kumar and Byrne, 2004), automatic speech recognition (Goel and Byrne, 2000), parsing (Titov and Henderson, 2006), etc.","[0, 12, 1]","[1, 1, 1]"
Moens and Steedman (1988) describes temporal expressions relating to changes of state.,[357],[1]
"Monolingual syntax-based distributional similarity is used in many proposals to find semantically related words (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)).",[26],[1]
Moore and Pollack (1992) gave an example of a simple discourse.,[1],[1]
"More experiments could be found in their paper (Morante and Daelemans, 2009).","[92, 21, 25]","[1, 1, 1]"
More linguistic knowledge (such as syntactic features) has been explored by Hulth (2003).,[0],[1]
"More recently, (Lapata and Keller, 2004) showed that simple unsupervised models perform significantly better when the frequencies are obtained from the web, rather than from a large standard corpus.",[197],[1]
"More recently, sentence simplification has also been shown helpful for summarization (Knight and Marcu, 2000), sentence fusion (Filippova and Strube, 2008b), semantic role labeling (Vickrey and Koller, 2008), question generation (Heilman and Smith, 2009), paraphrase generation (Zhao et al, 2009) and biomedical information extraction (Jonnalagadda and Gonzalez, 2009).",[9],[1]
"Morphological segmentation for these two languages was carried out using MeCab (MeCab, 2011) and the Stanford Word Segmenter (Tseng et al, 2005), respectively.","[0, 25]","[1, 1]"
"Most of the features we use are described in more detail in (Toutanova et al, 2005).","[41, 58]","[1, 1]"
"Much of the work involving comparable corpora has focused on extracting word translations (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000; Koehn and Knight, 2000; Gaussier et al., 2004; Shao and Ng, 2004; Shinyama and Sekine, 2004).",[13],[1]
"Much of this research explores sentiment classification, a text categorization task in which the goal is to classify a document as having positive or negative polarity (e.g., Das and Chen (2001), Pang et al (2002), Turney (2002), Dave et al (2003), Pang and Lee (2004)).","[116, 23]","[1, 1]"
"Much recent work on temporal relations revolved around the TimeBank and TempEval (Verhagen et al., 2007).",[8],[1]
"Multilingual parsers of participants in the CoNLL 2006 shared task (Buchholz and Marsi, 2006) can handle Japanese sentences.","[0, 183]","[1, 1]"
"My guess is that the features used in e.g., the Collins (2003) or Charniak (2000) parsers are probably close to optimal for English Penn Treebank parsing (Marcus et al, 1993), but that other features might improve parsing of other languages or even other English genres.",[264],[1]
"Note that the marginalization for a particular y would be tractable; it is used at training time in certain training objective functions, e.g., maximizing the conditional likelihood of a reference translation (Blunsom et al, 2008).",[57],[1]
"Note that the notion of density here is not to be confused with the conceptual density used by Agirre and Rigau (1996), which is essentially a semantic similarity measure by itself.","[242, 211]","[1, 1]"
"Note that these are the two extremes of semantic granularity in WordNet, and we plan to experiment with intermediate representation levels in future research (c.f. Li and Abe (1998), McCarthy and Carroll (2003), Xiong et al (2005), Fujita et al (2007)).",[30],[1]
"Numerous examples of the utility of word lattices come from the field of finite state automata, language modeling, speech recognition, parsing and machine translation (Mohri, 1997, inter alia).",[0],[1]
"Och (1999) described a method for determining bilingual word classes, used to improve the extraction of alignment templates through alignments between classes, not only between words.","[0, 14, 68]","[1, 1, 1]"
"Of course, if examples were also annotated with explanations in a consistent format, this could form the basis of a new evaluation of the kind essayed in the pilot study in (Giampiccolo et al, 2007).","[120, 119]","[1, 1]"
On the one hand machine learning is used to automate as much as possible the tasks an IE expert would perform in application development (Cardie 1997) (Yangarber et al 2000).,"[69, 154]","[1, 1]"
"On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives.",[0],[1]
"On the other hand, supervised models, typically treating error detection/correction as a classification problem, utilize the training of well-formed texts ((De Felice and Pulman, 2008) and (Tetreault et al, 2010)), learner texts, or both pair wisely (Brockett et al, 2006).",[56],[1]
One of the most popular methods leveraging bilingual parallel corpora is proposed by Bannard and Callison-Burch (2005).,[0],[1]
"One system (Hall et al, 2007b) extends this two-stage approach to a three-stage architecture where the parser and labeler generate an n-best list of parses which in turn is reranked.",[8],[1]
"Only one model was used for syntactic parsing in our system, in contrast to the existing work using an ensemble technique for further performance enhancement, e.g., (Hall et al, 2007).","[7, 8]","[1, 1]"
"Other resources for sentiment detection include the Dictionary of Affect in Language (DAL) to score the prior polarity of words, as in Agarwal et al (2011) on social media data.",[116],[1]
"Other resources such as COMLEX syntax dictionary (Grishman et al., 1994) and English Verb Classes and Alternations (EVCA) (Levin, 1993) can provide verb subategorization information and syntactic paraphrases, but they are indexed by words thus not suitable to use in generation directly.",[153],[1]
"Other systems have made a second tagging pass which uses information on token sequences tagged in the first pass (Borthwick 1999), or have used as features information about features assigned to other instances of the same token (Chieu and Ng 2002).",[69],[1]
"Our POS results, gathered using a Twitter-specific tagger (Gimpel et al, 2011), echo those of Ashok et al (2013) who looked at predict 14 Of course, simply inserting garbage isn't going to lead to more re-tweets, but adding more information generally involves longer text.",[5],[1]
"Our baseline experiments were modeled after those in (Finkel and Manning, 2009b), and while our results were not identical (we updated to a newer release of the data), we had similar results and found the same general trends with respect to how the joint model improved on the single models.",[133],[1]
Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC.,"[0, 60]","[1, 1]"
"Our first attempt is to directly apply the state of-art SRL system (Meza-Ruiz and Riedel, 2009) that trained on the CoNLL 08 shared task dataset (Surdeanu et al, 2008), hereafter called SRL-BS, to news tweets.",[216],[1]
"Our general estimation method also has practical applications in cases one uses a probabilistic context-free grammar to approximate strictly more powerful rewriting systems, as for instance probabilistic tree adjoining grammars (Schabes, 1992).",[159],[1]
"Our implementation is mostly in Python on top of the cdec system (Dyer et al, 2010) via the pycdec interface (Chahuneau et al, 2012).","[93, 73]","[1, 1]"
"Our machine translation system is a string-to dependency hierarchical decoder based on (Shen et al., 2008) and (Chiang, 2007).","[64, 4]","[1, 1]"
"Our results are an order of magnitude better than those reported by Riloff and Shepherd (1997) and Roark and Charniak (1998), who report average accuracies of 17% and 35% respectively.",[12],[1]
"Our word pairs are lemmatized using the Wordnet based lemmatizer of NLTK (Loper and Bird, 2002).",[106],[1]
"Our work focuses on a recent line of exploratory work in the direction of Unrestricted Relation Discovery which is defined as: the automatic identification of different relations in text without specifying a relation or set of relations in advance (Shinyama and Sekine, 2006).",[0],[1]
"Our work is closest in spirit to the two papers that inspired us (Barzilay and Lee, 2003).",[25],[1]
"PKI - Inverted Indexing (Kudo and Matsumoto, 2003), stores for each feature the support vectors in which it appears.",[162],[1]
"Pairwise mean kappa scores were calculated by comparing a coder's segmentation against a reference segmentation formulated by the majority opinion strategy used in Passonneau and Litman (1993, p. 150) (Hearst, 1997, pp. 53-54).",[124],[1]
"Pairwise ranking optimization (PRO) proposed by (Hopkins and May, 2011) is a new method for discriminative parameter tuning in statistical machine translation.",[0],[1]
Pang et al (2002) and Turney (2002) classified sentiment polarity of reviews at the document level.,[23],[1]
"Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she.",[11],[1]
"Pantel et al (2007) and Szpektor et al (2008) represented the context of such rules as the intersection of preferences of the rule's LHS and RHS, namely the observed argument instantiations or their semantic classes.","[36, 7]","[1, 1]"
"Part of speech tags are assigned by Brill's tagger (Brill, 1992).",[0],[1]
Passonneau and Litman (1997) found that pause length correlates with discourse segment boundaries.,"[152, 399]","[1, 1]"
"Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al 2004).",[6],[1]
"Pedersen (2000) presents experiments with an ensemble of Naive Bayes classifiers, which outperform all previous published results on two ambiguous words (line and interest).",[19],[1]
"Performing policy-gradient with this function is equivalent to training a fully supervised, stochastic gradient algorithm that optimizes conditional likelihood (Branavan et al, 2009).",[99],[1]
Pitler and Nenkova (2008) consider a different task of predicting text quality for an educated adult audience.,[0],[1]
"Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is translated into features for a machine learning experiment in assigning semantic roles.",[29],[1]
"Preliminary experiments with tags derived automatically using distributional clustering (Clark, 2000), have shown essentially the same results.",[72],[1]
"Previous shared tasks have shown that frame-semantic SRL of running text is a hard problem (Baker et al, 2007), partly due to the fact that running text is bound to contain many frames for which no or little annotated training data are available.",[50],[1]
"Previous work (Kudo et al, 2004) showed CRFs outperform generative Markov models and discriminative history-based methods in JWS.",[128],[1]
"Prior work addressed this by using the single parameter Poisson distribution, forcing infrequent words to share a global parameter estimated from the fertility of all words in the corpus (Zhao and Gildea, 2010).",[180],[1]
"Probabilities for the PCFG rules are computed monolingually as in the standard Goodman reduction for DOP (Goodman, 1996).",[135],[1]
"QBC is based on the idea to select those examples for manual annotation on which a committee of classifiers disagree most in their predictions (Engelson and Dagan, 1996).",[49],[1]
"Quantitatively, subjective sentences in the product reviews amount to 78% (McDonald et al, 2007), while subjective sentences in the movie review dataset are only about 25% (Mao and Lebanon, 2006).",[7],[1]
"Quasi-synchronous grammar (QG) provides this backbone (Smith and Eisner, 2006); we describe a coarse-to-fine approach for decoding within this framework, advancing substantially over earlier QG machine translation systems (Gimpel and Smith, 2009).",[81],[1]
"RAP (Kennedy and Boguraev, 1996), Baldwin's pronoun resolution method (Baldwin, 1997) and Mitkov's knowledge-poor pronoun resolution approach (Mitkov, 1998b).","[46, 123]","[1, 1]"
"ROUGE utilizes, skip n-grams, which allow for matches of sequences of words that are not necessarily adjacent (Lin and Och, 2004a).",[62],[1]
Radev et al (2000) use it in their MDS system MEAD.,"[46, 12]","[1, 1]"
Ravichandran and Hovy (2002) present an alternative ontology for type preference and describe a method for using this alternative ontology to extract particular answers using surface text patterns.,[0],[1]
"Recent progress in better parameterisation and approximate inference (Blunsom et al., 2009) can only augment the performance of these models to a similar level as the baseline where bidirectional word alignments are combined with heuristics and subsequently used to induce translation equivalence (e.g. (Koehn et al., 2003)).","[7, 123]","[1, 1]"
"Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002).","[257, 132]","[1, 1]"
"Recently, most evaluations of machine translation systems (Callison-Burch et al, 2009) indicate that the performance of corpus-based statistical machine translation (SMT) has come up to the traditional rule-based method.","[5, 0]","[1, 1]"
"Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al, 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005).",[19],[1]
"Recognizing textual entailment is to determine whether a sentence (sometimes a short paragraph) can entail the other sentence (Giampiccolo et al, 2007).",[0],[1]
"Researchers employ the existing SMT models for PG (Quirk et al, 2004).","[61, 7]","[1, 1]"
"Resnik (1999) mined comparable corpora on the assumption that the pages which are comparable of each other share a similar structure (headers, paragraphs, etc.) when text is presented in many languages in the Web.",[0],[1]
Riezler et al (2003) applied linguistically rich LFG grammars to a sentence compression system.,[34],[1]
"Roth and Yih (2004) formulated the problem of extracting entities and relations as an integer linear program, allowing them to use global structural constraints at inference time even though the component classifiers were trained independently.",[0],[1]
"SRL based on FrameNet is thus not a novel task, although very few systems are known capable of completing a general frame-based annotation process over raw texts, noticeable exceptions being discussed for example in (Erk and Pado, 2006), (Johansson and Nugues, 2008b) and (Coppola et al., 2009).",[122],[1]
"Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine Now the second author is affiliated with NTT.","[34, 45]","[1, 1]"
"Semantic role analysis has the potential of benefiting a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005).",[39],[1]
"Semantic word vector spaces are at the core of many useful natural language applications such as search query expansions (Jones et al 2006), fact extraction for information retrieval (Pas?ca et al 2006) and automatic annotation of text with disambiguated Wikipedia links (Ratinov et al 2011), among many others (Turney and Pantel, 2010).",[7],[1]
"Similar IR features are also used by other WePS systems as they are more robust to the variety of web pages (Artiles et al, 2007).",[84],[1]
Similar methods to Shen et al (2007) have also been used in Shen and Joshi (2008) and Goldberg and Elhadad (2010).,"[167, 56]","[1, 1]"
"Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2.","[109, 21]","[1, 1]"
"Since many tagging systems utilise gazetteers of known entities, some research has focused on their automatic extraction from the web (Etzioni et al, 2005) or Wikipedia (Toral et al, 2008), although Mikheev et al (1999) and others have shown that larger NE lists do not necessarily correspond to increased NER performance.","[18, 153]","[1, 1]"
"Since the task is basically identical to shallow parsing by CRFs, we follow the feature sets used in the previous work by Sha and Pereira (2003).",[12],[1]
"Skip-bigrams (Lin and Och, 2004) are pairs of words in sentence order allowing for gaps in between.",[112],[1]
"Smith and Eisner (2008) also proposed other variants with more factors, which we omit for brevity.",[148],[1]
"Some prior studies use every word in a document/sentence as the features, such as the distributional approaches (Pantel et al, 2009).",[41],[1]
Speech was found to improve inter-annotator agreement in discourse segmentation of monologues (Hirschberg and Nakatani 1996).,[0],[1]
"Statistical significance on the BLEU scores was tested using pairwise bootstrap sampling (Koehn, 2004).",[51],[1]
"Stevenson and Wilks (2001) presented a classifier combination framework where disambiguation methods (simulated annealing, subject codes and selectional restrictions) were combined using the TiMBL memory-based approach (Daelemans et al, 1999).",[315],[1]
"Subsequently, Prasad et al (2010b) used Callison-Burch's technique for identifying syntax-constrained paraphrases (Callison-Burch, 2008) to identify additional discourse connectives, some of which don't appear in the PDTB corpus and some of which appear in the corpus but were not identified and annotated as discourse connectives.",[7],[1]
"Subsequently, a method was developed to use a special case of the ITGR the aforementioned BTGR for the translation task itself (Wu, 1996).",[77],[1]
Such words are called signature terms in Lin and Hovy (2000) who were the first to introduce the log-likelihood weighting scheme for summarization.,[261],[1]
"Summarization evaluation is done using ROUGE-2 (R-2) (Lin and Hovy, 2003).",[0],[1]
"Syntactic Parallelism (Lappin and Leass, 1994).",[107],[1]
"TBL is a machine learning approach that has been employed to solve a number of problems in natural language processing; most famously, it has been used for part-of-speech tagging (Brill, 1995).","[36, 0]","[1, 1]"
"Table 1 shows the f-scores for U-DOP* and UML-DOP against the f-scores for U-DOP reported in Bod (2006), the CCM model in Klein and Manning (2002), the DMV dependency model in Klein and Manning (2004) and their combined model DMV+CCM.","[115, 114]","[1, 1]"
"Table 1: The patterns we used for entailment acquisition based on (Hearst, 1992) and (Pantel et al, 2004).","[20, 113]","[1, 1]"
"Table 2 shows the best results among the configurations we have tested (expressed using the official evaluation measures, see (Callison-Burch et al, 2012) for details).","[127, 6]","[1, 1]"
Table 8 compares the F1 results of our baseline model with Nakagawa and Uchimoto (2007) and Zhang and Clark (2008) on CTB 3.0.,[121],[1]
Takamura et al (2005) used the Ising model to extract semantic orientations of words (not phrases).,"[61, 28]","[1, 1]"
The A* heuristics explored by Klein and Manning (2003a) can be seen as resulting from bounding transformations.,[65],[1]
"The B&C scheme is similar to the original DepBank scheme (King et al, 2003), but overall contains less grammatical detail; Briscoe and Carroll (2006) describes the differences.",[104],[1]
The BioScope corpus has been used to train and evaluate automatic classifiers (e.g. Ozgur and Radev (2009) and Morante and Daelemans (2009)) with promising results.,[21],[1]
"The CCG grammar used by our system is read off the derivations in CCGbank, following Hockenmaier and Steedman (2002), meaning that the CCG combinatory rules are encoded as rule instances, together with a number of additional rules which deal with punctuation and type-changing.","[22, 0]","[1, 1]"
"The CCG parser we use (Clark and Curran, 2007b) makes use of three levels of representation: one, a POS tag level based on the fairly coarse-grained POS tags in the Penn Treebank; two, a lexical category level based on the more fine-grained CCG lexical categories, which are assigned to words by a CCG super tagger; and three, a hierarchical level consisting of CCG derivations.",[146],[1]
"The Chinese Nombank extends the general annotation framework of the English Proposition Bank (Palmer et al, 2005) and the English Nombank (Meyers et al, 2004) to the annotation of nominalized predicates in Chinese.","[156, 163]","[1, 1]"
"The CoNLL 2011 Shared Task (Pradhan et al,2011) is dedicated to modeling unrestricted coreference in OntoNotes.",[0],[1]
"The CoNLL-2007 shared tasks include two tracks: the Multilingual Track and Domain AdaptationTrack (Nivre et al, 2007).",[0],[1]
"The Context-Sensitive extension (Krahmer and Theune, 2002) is able to generate referring expressions for the most salient entity in a context; the Boolean Expressions algorithm (van Deemter, 2002) is able to derive expressions containing boolean operators, as in the cup that does not have a handle; and the Sets algorithm (van Deemter, 2002) extends the basic approach to references to sets, as in the red cups.",[0],[1]
"The Deep Read reading comprehension prototype system (Hirschman et al, 1999) achieves a level of 36% of the answers correct using a bag-of-words approach together with limited linguistic processing.",[0],[1]
"The Espresso algorithm (Pantel and Pennacchiotti, 2006) achieves a precision of 80% in learning part whole relations from the Acquaint (TREC-9) corpus of nearly 6M words.","[9, 54]","[1, 1]"
"The First d Uncovered Words strategy (FdUW) is described by Tillman and Ney (2003) and Zens and Ney (2004), who call it the IBM Constraint.",[185],[1]
"The MDL-based tree cut model was originally introduced for handling the problem of generalizing case frames using a thesaurus (Li and Abe, 1998).",[0],[1]
"The OVIS annotations are in contrast with other corpora and systems (e.g. Miller et al. 1996), in that our annotation convention exploits the Principle of Compositionality of Meaning.","[8, 59]","[1, 1]"
The OntoNotes 90% solution (Hovy et al 2006) actually means such a degree of granularity that enables a 90% IAA.,[0],[1]
"The VPs with the verbs start or finish (see Pustejovsky, 1991) can also be accounted for using the qualia structure.",[391],[1]
"The Vieira/Poesio algorithm (Vieira and Poesio, 2000) attempts to classify each definite description as either direct anaphora, discourse-new, or bridging description.","[77, 536]","[1, 1]"
"The actual realization of the component is based on a constraint-based inheritance algorithm that follows the example of PATR-II (Shieber et al, 1989).",[21],[1]
"The answer does not always solve the original problem Eq (2), but previous works (e.g., (Rush et al 2010)) has shown that it is effective in practice.","[174, 234, 150]","[1, 1, 1]"
"The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al, 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances.",[26],[1]
"The average senior high school student achieves 57% correct (Turney, 2006).",[411],[1]
The bootstrapping methods for language independent NER of Cucerzan and Yarowsky (1999) have a similar effect.,[0],[1]
The cluster ranking model of Rahman and Ng (2009) proceeds in a left-to-right fashion and adds the current discourse old mention to the highest scoring preceding cluster.,[214],[1]
"The complex SRL architectures proposed (usually combining local and global, i.e. joint, models of argument classification, e.g. (Toutanova et al., 2008)) require a large number of annotated examples.",[520],[1]
"The data sets for the COREF task are produced based on three resources: MedCO coreference annotation (Su et al, 2008), Genia event annotation (Kim et al, 2008), and Genia Treebank (Tateisi et al., 2005).",[131],[1]
The dataset that Cohn and Lapata (2008) used to learn transduction rules consists of 570 pairs of source sentences and abstractive compressions.,"[118, 33]","[1, 1]"
"The decomposition into two knowledge sources in Equation 2 is known as the source-channel approach to statistical machine translation (Brown et al, 1990).",[0],[1]
"The definitions of the objective function (4) and the gradient (5) for training remain the same in the partial-data case; the only differences are that (pi) is now defined to be those derivations which are con sis tent with the partial dependency structure pi, and the gold-standard dependency structures pij are the partial structures extracted from the gold-standard lexical category sequences. Clark and Curran (2004b) gives an algorithm for finding all derivations in a packed chart which produce a particular set of dependencies.",[76],[1]
"The degree of parallelism can vary greatly, ranging from noisy parallel documents that contain many parallel sentences, to quasi parallel documents that may cover different topics (Fung and Cheung, 2004).",[81],[1]
The dependency parser of this demonstration is a further development of Carreras (2007) and Johansson and Nugues (2008).,"[41, 171]","[1, 1]"
"The end result of our selection and aggregation module (see section 6.2) is a fully specified logical form which is to be sent to the Semantic-Head Driven Generation component of Gemini (Shieber et al, 1990).",[0],[1]
"The evaluations were carried out with the SVMlight-TK software (Moschitti, 2004) available at http: //ai-nlp.info.uniroma2.it/moschitti/ which encodes the tree kernels in the SVM-light software (Joachims, 1999).",[134],[1]
"The experiments were evaluated using BLEU (Papineni et al, 2002) and METEOR (Lavieand Agarwal, 2007) 12.","[11, 7]","[1, 1]"
The extraction patterns used by both Yangarber et al (2000) and Stevenson and Greenwood (2005) were based on SVO tuples extracted from dependency trees.,[69],[1]
"The fact that no improvement was obtained agrees with previous observations that classifiers that are too accurate can not be improved with bootstrapping (Pierce and Cardie,2001).",[65],[1]
"The fact that observations and prior knowledge are useful for part-of-speech tagging is well understood (Brill, 1995), but the approach of estimating an initial transition model only from unambiguous word pairs is novel.",[109],[1]
"The feature structure (adopted from Karttunen, 1984, p. 30) represents disjunctions by enclosing the alternatives in curly brackets ({}).",[49],[1]
"The final approach we re-implement is the one proposed by Baroni and Zamparelli (2010), who treat attributive adjectives as functions from noun meanings to noun meanings.",[21],[1]
"The findings described in (Keller and Lapata, 2003) seem to suggest that count estimations we need in the present study over Subject-Verb bigrams are highly correlated to corpus counts.","[412, 414, 206]","[1, 1, 1]"
"The first approach to predict user judgments on the basis of interaction metrics is the well-known PARADISE model (Walker et al, 1997).",[6],[1]
"The first decoder, Hiero Cube Pruning (HCP), is a k-best decoder using cube pruning implemented as described by Chiang (2007).","[189, 181]","[1, 1]"
"The first feature is the absolute difference between ai and ai-1 + 1 and is similar to information used in other HMM word alignment models (Och and Ney, 2000) as well as phrase translation models (Koehn, 2004).","[8, 17]","[1, 1]"
"The first is the LOB corpus (Johansson 1986), which we used in the earlier experiments as well (van Halteren, Zavrel, and Daelemans 1998) and which has proved to be a good testing ground.",[63],[1]
"The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al, 2007).",[135],[1]
"The idea of bidirectional parsing is related to the bidirectional sequential classification method described in (Shen et al, 2007).",[0],[1]
"The intrinsic evaluation measures used in our experiments are the well-known BLEU (Papineni et al., 2001) and NIST (Doddington, 2002) metrics, and an F-score measure that adapts evaluation techniques from dependency-based parsing (Crouch et al., 2002) and sentence-condensation (Riezler et al, 2003) to machine translation.",[78],[1]
"The list of polarity words that we use in this component has been taken from the OpinionFinder system (Wilson et al, 2005).","[44, 39]","[1, 1]"
"The maximum entropy parser (Ratnaparkhi, 1997) is used in this study, for it offers the flexibility of integrating multiple sources of knowledge into a model.",[0],[1]
"The modeling power of CRFs has been of great benefit in several applications, such as shallow parsing (Sha and Pereira, 2003) and information extraction (McCallum and Li, 2003).","[68, 7]","[1, 1]"
"The modern Bible is tagged using the C & C maximum entropy tagger (Curran and Clark, 2003), and these tags are transferred from source to target through high-confidence alignments aquired from two alignment approaches.","[118, 114]","[1, 1]"
The morphology algorithm proposed by Kay and Roscheisen (1993) is applied for splitting potential suffixes and prefixes and for obtaining the normalised word forms.,[246],[1]
"The most common techniques for bidirectional alignment are post-hoc combinations, such as union or intersection, of directional models, (Och et al, 1999), or more complex heuristic combiners such as grow-diag-final (Koehn et al, 2003).","[55, 37]","[1, 1]"
The most direct points of comparison of our method are the approaches of Johnson et al (1999) and Johnson and Riezler (2000).,[105],[1]
"The most successful translation models that are found in the literature exploit finite-state machinery. The approach started with the so-called IBM models (Brown et al, 1988), implementing a set of elementary operations, such as movement, duplication and translation, that independently act on individual words in the source sentence.",[52],[1]
"The obtained accuracy is around 96% and was computed indirectly by checking disagreement with the Brown sentence aligner (Brown et al, 1991) on randomly selected 500 disagreement cases.","[19, 7]","[1, 1]"
The of ITG decoding algorithm of Wu (1996) can be viewed as a variant of the Viterbi parsing algorithm for alignment selection.,[131],[1]
The only exception is in (Wacholder et al 1997) where the reported performance for the sole semantic disambiguation task of PNs is 79%.,"[57, 59]","[1, 1]"
"The only publication, we are aware of, is (Ueffing et al, 2002).","[51, 49]","[1, 1]"
"The other dimensions of both domains were difficult to interpret. We experimented with using the SCL features together with the raw features (n-grams and length), as suggested by (Blitzer et al, 2006).",[178],[1]
"The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based.",[15],[1]
"The patterns we used for entailment acquisition based on (Hearst, 1992) and (Pantel et al, 2004).","[120, 30]","[1, 1]"
"The performance of many natural language processing tasks, such as shallow parsing (Zhang et al., 2002) and named entity recognition (Florianet al, 2004), has been shown to depend on integrating many sources of information.","[35, 22, 9, 118]","[1, 1, 1, 1]"
"The pioneering work on fusion is Barzilay and McKeown (2005), which introduces the frame work used by subsequent projects: they represent the inputs by dependency trees, align some words to merge the input trees into a lattice, and then extract a single, connected dependency tree as the output.",[198],[1]
"The present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (McDonald et al, 2005), (Nivre et al, 2007), and (Zhang and Nivre, 2011), and two constituency parsers (Charniak and Johnson, 2005) and (Klein and Manning, 2003), whose outputs we reconverted to dependency structures by Penn Converter (Johansson and Nugues, 2007).",[7],[1]
"The problems of non-nominal terms (Klavans and Kan, 1998), term variation (Jacquemin et al, 1997), and relevant contexts (Maynard and Ananiadou, 1998), can be considered for improving the performance.","[18, 19]","[1, 1]"
"The program takes the output of char_align (Church, 1993), a robust alternative to sentence-based alignment programs, and applies word-level constraints using a version of Brown's Model 2 (Brown et al, 1993), modified and extended to deal with robustness issues.","[573, 578]","[1, 1]"
"The proposed method in (Takamura et al, 2005) extracts semantic orientations from a small number of seed words with high accuracy in the experiments on English as well as Japanese lexicons.","[4, 190, 188, 28]","[1, 1, 1, 1]"
"The recent availability of more corpora has enabled much information about dependency relations to be obtained by using a Japanese dependency analyzer such as KNP (Kurohashi and Nagao, 1994) or CaboCha (Kudo and Matsumoto,2002).",[0],[1]
The reported coverage in Attardi (2006) is already very high when the system is restricted to transitions of degree two or three.,[90],[1]
"The results we report are with the Gaussian prior regularization term described in (Johnson et al, 1999).",[105],[1]
"The same beam-search pruning as described in (Tillmann and Ney, 2003) is used.","[264, 276, 240]","[1, 1, 1]"
"The same technique was also used by the winning team of the CoNLL 2007 Shared Task (Hall et al, 2007), combining six transition-based parsers.",[8],[1]
"The search algorithm for the best ITG alignment, a best-first chart parsing (Charniak et al., 1998), was augmented with an A* search heuristic of quadratic complexity (Klein and Manning, 2003), resulting in significant reduction in computational complexity.","[12, 161]","[1, 1]"
"The second, sys comb giza, corresponds to the pair-wise symmetric HMM alignments from GIZA++ described in (Matusov et al, 2006).","[54, 43]","[1, 1]"
"The sentence has 42 readings (Hobbs and Shieber, 1987), and it is easy to imagine how the number of readings grows exponentially (or worse) in the length of the sentence.",[24],[1]
"The shared task at the 2010 Conference on Natural Language Learning (CoNLL) focused on speculation detection for the domain of biomedical research literature (Farkas et al, 2010), with data sets based on the BioScope corpus (Vincze et al, 2008) which annotates so called speculation cues along with their scopes.",[29],[1]
"The states could be more refined than those shown above: the state for the subject, for example, should probably be not NP but a pair (Npl, NP3s) .STSG is simply a version of synchronous tree adjoining grammar or STAG (Shieber and Schabes, 1990) that lacks the adjunction operation.",[0],[1]
"The string-to-tree (Galleyet al 2006) and tree-to-tree (Chiang, 2010) methods have also been the subject of experimentation, as well as other formalisms such as Dependency Trees (Shen et al, 2008).","[21, 27]","[1, 1]"
"The training and testing data are run through tweet-specific tokenization, similar to that used in the CMU Twitter NLP tool (Gimpel et al, 2011).",[5],[1]
The translation probability can also be discriminatively trained such as in Tillmann and Zhang (2006).,"[39, 0]","[1, 1]"
"The use of machine learning techniques — mainly statistical — for this task is a more recent development, either alongside the traditional hand-grammar approach to learn to distinguish specific difficult cases (Mani and Wilson, 2000), or on its own (Hacioglu et al., 2005).",[15],[1]
The very interesting study by Snyder and Barzilay (2008) on multilingual approaches to morphological segmentation was difficult to classify.,[0],[1]
"The web as a corpus has been successfully used for many areas in NLP (Kilgarriff and Grefenstette 2003) such as WSD (Mihalcea and Moldovan 1999), obtaining frequencies for bigrams (Keller and Lapata 2003) and noun compound bracketing (Nakov and Hearst 2005).",[140],[1]
The word alignment was trained with six iterations of IBM model 1 (Brown et al 1993).,"[578, 567]","[1, 1]"
"The work of Pustejovsky [Pustejovsky, 1991] is related in its attempt o reduce the size and complexity of individual lexical entries.","[205, 391]","[1, 1]"
"Their features are usually extended from Gildea and Jurafsky (2002)'s work, which uses flat information derived from a parse tree.",[167],[1]
"Their models are trained on the entire Penn Treebank data (instead of using only the 24,115-token test data), and so are the tagging models used by Goldberg et al (2008).","[171, 153]","[1, 1]"
"There are many POS taggers developed using different techniques for many major languages such as transformation-based error-driven learning (Brill, 1995), decision trees (Black et al, 1992), Markov model (Cutting et al, 1992), maximum entropy methods (Ratnaparkhi, 1996) etc for English.","[87, 188]","[1, 1]"
"There is some evidence (Baldwin et al, 2003) that part of speech tagging might improve results in this kind of task.",[57],[1]
"Therefore, there is nowadays a pressing need to adopt learning approaches to extend the coverage of the FrameNet lexicon by automatically acquiring new LUs, a task we call LU induction, as recently proposed at SemEval-2007 (Baker et al, 2007).",[0],[1]
"These challenges have prompted some researchers to move away from MERT, in favor of linearly decomposable approximations of the evaluation metric (Chiang et al., 2009; Hopkins and May, 2011; Cherry and Foster, 2012), which correspond to easier optimization problems and which naturally incorporate regularization.","[21, 23]","[1, 1]"
"These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) that we use in this work.",[19],[1]
"These results are comparable to the results from Gildea and Palmer (2002), but only roughly because of differences in corpora.",[76],[1]
"These strategies can be seen as transactions made up of conversational games (Carletta et al., 1997).",[32],[1]
"They include those using Naive Bayes (Gale et al. 1992a), Decision List (Yarowsky 1994), Nearest Neighbor (Ng and Lee 1996), Transformation Based Learning (Mangu and Brill 1997), Neural Network (Towell and Voorhess 1998), Winnow (Golding and Roth 1999), Boosting (Escudero et al 2000), and Naive Bayesian Ensemble (Pedersen 2000).","[53, 49]","[1, 1]"
"They often belong to controversial subjects (e.g., religion, terrorism, etc.) where the same event can beseen from two or more opposing perspectives, like the IsraeliPalestinian conflict (Lin et al, 2006).",[30],[1]
"They surpassed their earlier work in 2003 with acyclic dependency network tagger, achieving 97.2% /89.05% (seen/unseen) (Toutanova et al, 2003).",[38],[1]
"They use two kinds of features: syntactic ones and word based ones, for example, the path of the given pair of NEs in the parse tree and the word n-gram between NEs (Kambhatla, 2004).",[46],[1]
"This application is important for the automatic evaluation of machine translation and summarization, since we can paraphrase the human translations/summaries to make them more similar to the system outputs, which can refine the accuracy of the evaluation (Kauchak and Barzilay, 2006).",[0],[1]
"This approach has been explored in (Zajic et al, 2002) and (Banko et al, 2000).","[15, 17]","[1, 1]"
"This approach was first used by Morante et al (2008) and subsequently in many of the studies presented in the CoNLL-2010 Conference Shared Task (Farkas et al, 2010a), and is the one used in this paper.","[145, 23]","[1, 1]"
"This assumption is realistic: while truly parallel data (humanly created) might be in short supply or harder to acquire, adapting statistical machine translation (SMT) systems from one language-pair to another is not as challenging as it used to be (Al-Onaizan and Papineni, 2006).",[0],[1]
"This behavior appears to be consistent on the test 2007 and nc-test2007 data sets across systems (Callison-Burch et al, 2007).",[107],[1]
"This contrasts with Open Information Extraction (Banko and Etzioni, 2008) and On-Demand Information Extraction (Sekine, 2006), which aim to extract large databases of open-ended facts, and with supervised relation extraction, which requires additional supervised data to learn new relations.",[0],[1]
"This environment reward function is a simplification of the one described in Branavan et al (2009), and it performs comparably in our experiments.",[33],[1]
"This estimate could be used as a starting point for a more detailed alignment algorithm such as word_align (Dagan et al, 1993).","[53, 4]","[1, 1]"
"This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al, 2008) and transfer (Hwa et al, 2005) systems for prediction of linguistic structure.","[128, 0]","[1, 1]"
"This is a strong constraint on the matching of syntax so it is not surprising that the model has good precision but very low recall on the ACE corpus (Zhao and Grishman, 2005).",[61],[1]
"This is in the tradition of the Textual Entailment or Information Validation paradigm (Dagan et al., 2009), and in contrast to aboutness annotation such as semantic roles (Carreras and Marquez, 2004) or the BioNLP2009 task (Kim et al, 2009) where negated relations are also labelled as positive.","[9, 73]","[1, 1]"
"This kind of strategy has been widely used in the applications of machine learning to named entity recognition and has also been used in Chinese word segmentation (Xue and Shen, 2003).","[46, 91, 0]","[1, 1, 1]"
"This measurement is called longest common subsequence ratio [Melamed, 1995].","[129, 130]","[1, 1]"
"This metric is broadly comparable to the predicate-argument dependencies of CCGBank (Hockenmaier and Steed man, 2007) or of the ENJU grammar (Miyao and Tsujii, 2008), and also somewhat similar to the grammatical relations (GR) of the Briscoe and Carroll (2006) version of DepBank.",[595],[1]
"This model aims to resolve both coreferent and associative (also called bridging (Poesio and Vieira, 1998)) cases of nonpronominal anaphora.",[146],[1]
"This network could also be used more directly for topic segmentation as in (Job- bins and Evett, 1998).",[0],[1]
This preprocessing technique we use here is the best performer amongst other explored techniques presented in Habash and Sadat (2006).,[55],[1]
This problem has been studied by Jelinek and Lafferty (1991) and by Stolcke (1995) .,"[13, 21]","[1, 1]"
"This section presents our results on the GE and the EPI tasks (Kim et al, 2011b; Ohta et al, 2011) respectively. Different experimental methods in processing the obtained event rules are described for the purpose of improving the precision of both tasks and increasing the recall of the EPI task.",[15],[1]
"This task is based on task A in the TempEval-2 challenge (Verhagen et al, 2010).","[0, 5]","[1, 1]"
"This was what (Haghighi and Klein, 2009) did and we did this in training with the REUTERS corpus (Hasler et al, 2006) in which syntactic roles are annotated.",[72],[1]
"Three automatic segmenters were trained - or had their parameters estimated upon - The Moonstone data set, including MinCut; (Malioutov and Barzilay, 2006), BayesSeg; (Eisenstein and Barzilay, 2008), and APS (Kazantseva and Szpakowicz, 2011).","[191, 164]","[1, 1]"
"Three most noticeable efforts in manual evaluation are SEE (Lin and Hovy, 2001), Factoid (Van Halteren and Teufel, 2003), and the Pyramid method (Nenkova and Passonneau, 2004).","[201, 63]","[1, 1]"
"Thus structure-based kernels can well model syntactic parse tree in a variety of applications, such as relation extraction (Zelenko et al, 2003), named entity recognition (Culotta and Sorensen, 2004), semantic role labeling (Moschitti et al, 2008) and so on.","[105, 30]","[1, 1]"
"Thus, ? can recursively be an SRK (and evaluate Nested PASs (Moschitti et al, 2007)) or any other potential kernel (over the arguments).",[19],[1]
Tillmann and Zhang (2006) present a procedure to directly optimize the global scoring function used by a phrase based decoder on the accuracy of the translations.,[2],[1]
"To address this issue, a coarse-grained English all-words task (Navigli et al, 2007) was conducted during SemEval-2007.","[0, 1]","[1, 1]"
"To apply these scorers to automatically extracted NPs ,different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al (2009)).","[14, 78]","[1, 1]"
"To compute the features which we extract in the next section, all instances in our data sets were part-of-speech tagged by the MXPOST tagger (Ratnaparkhi, 1996), parsed with the MaltParser, and named entity tagged with the Stanford NE tagger (Finkel et al, 2005).",[129],[1]
"To find the minimum value, we can use a subgradient method (Rush et al 2010).","[167, 174]","[1, 1]"
"To handle the increased computational complexity, we adopt the incremental parsing framework with dynamic programming (Huang and Sagae, 2010), and propose an efficient method of character-based decoding over candidate structures.",[0],[1]
"To improve the quality of the induced trees, we combine our PCFG induction with the CCM model of Klein and Manning (2002), which has complementary stengths: it identifies brackets but does not label them.",[0],[1]
"To improve this performance, we plan to enrich the Arabic lexicon with more proper names, using either name recognition (Maloney and Niv, 1998) or a back translation approach after name recognition in English texts (Al-Onaizan and Knight, 2002).",[0],[1]
"To obtain syntactic parse trees and semantic roles on the tuning and test datasets, we first parse the source sentences with the Berkeley Parser (Petrov and Klein, 2007), trained on the Chinese Treebank 7.0 (Xue et al, 2005).","[142, 172]","[1, 1]"
"To overcome the shortcomings of available resources and to take advantage of ensemble systems, Wan (2008) and Wan (2009) explored methods for developing a hybrid system for Chinese using English and Chinese sentiment analyzers.",[49],[1]
"To produce this, we segment sentences with MXTerminator (Reynar and Ratnaparkhi, 1997) and parse the corpus with the self trained Charniak parser (McClosky et al, 2006).",[10],[1]
"To remove this variable, we carry out a second evaluation against the Briscoe and Carroll (2006) re annotation of DepBank (King et al, 2003), as described in Clark and Curran (2007a).","[20, 104]","[1, 1]"
"To resolve this problem, Bunescu and Mooney (2007), Riedel et al (2010) and Yao et al (2010) relaxed the DS assumption to the at least-one assumption and employed multi-instance learning techniques to identify wrongly labeled instances.",[11],[1]
"To save time, we use a pruning stage (Xue and Palmer, 2004) to filter out the constituents that are clearly not semantic arguments to the predicate.",[49],[1]
"To the best of our knowledge no system was able to reproduce the successful results of (Swier and Stevenson, 2004) on the PropBank role set.",[112],[1]
"Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004).","[66, 69]","[1, 1]"
Top accuracy on the entire data set (an) and on the semantic subset (ansem) was reached by Mikolov et al (2013c) using a skip-gram predict model.,[24],[1]
"Topic models have also been applied to other classes of semantic task, for example word sense disambiguation (Li et al., 2010), word sense induction (Brody and Lapata, 2009) and modelling human judgements of semantic association (Griffiths et al, 2007).",[64],[1]
Toutanova and Moore (2002) improve the model by incorporating pronunciation information.,[0],[1]
"Towards this, Wiebe and Mihalcea (2006) conduct a study on human annotation of 354 words senses with polarity and report a high inter-annotator agreement.",[66],[1]
"Traditional learning-based coreference resolvers operate by training a model for classifying whether two mentions are co-referring or not (e.g., Soon et al (2001), Ng and Cardie (2002b), Kehler et al (2004), Ponzetto and Strube (2006)).","[48, 4, 36]","[1, 1, 1]"
"Translation Edit Rate (TER, Snover et al (2006)) based alignment proposed in Sim et al (2007) is often taken as the baseline, and a couple of other approaches, such as the Indirect Hidden Markov Model (IHMM, He et al (2008)) and the ITG-based alignment (Karakos et al. (2008)), were recently proposed with better results reported.","[107, 7, 138, 158]","[1, 1, 1, 1]"
Tsuruoka and Tsujii (2005) proposed easiest-first deterministic decoding.,"[72, 88]","[1, 1]"
Two evaluation tasks for Barzilay and Lapata (2008)'s entity-based model are sentence ordering and summary coherence rating.,[395],[1]
"ULISSE was tested against the output of two really different data-driven parsers: the first order Maximum Spanning Tree (MST) parser (McDonald et al., 2006) and the DeSR parser (Attardi, 2006) using Support Vector Machine as learning algorithm.",[98],[1]
"Unfortunately, the models presented in the previous work, such as Zeman and Resnik (2008), McDonald et al (2011) and Tackstrom et al (2012), were not made available, so we reproduced the direct transfer algorithm of McDonald et al (2011), using Malt parser (Nivre, 2008) and the same set of features.","[80, 81]","[1, 1]"
"Unidirectional word alignments were provided by MGIZA++ (Gao and Vogel, 2008), then symmetrized with the grow-diag-final-and heuristic (Koehn et al, 2005).","[16, 9]","[1, 1]"
Unsupervised HMMs were applied to conversational data by Ritter et al (2010) who experimented with Twitter conversations.,[0],[1]
"Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a supervised sequence labeling approach while Ozgur and Radev (2009) developed a rule-based system that exploits syntactic patterns.",[21],[1]
"Using constraint satisfaction techniques for natural language parsing was introduced first in (Maruyama, 1990) by defining a constraint dependency grammar (CDG) that maps nicely on the notion of a CSP.",[140],[1]
"Using functional centering (Strube and Hahn, 1999) to rank the CFs led to no improvements, because of the almost perfect correlation in our domain be tween subject hood and being discourse-old.",[154],[1]
"Variations of SCFGs go back to Aho and Ullman (1972)'s Syntax-Directed Translation Schemata, but also include the Inversion Transduction Grammars in Wu (1997), which restrict grammar rules to be binary, the synchronous grammars in Chiang (2005), which use only a single nonterminal symbol, and the Multi text Grammars in Melamed (2003), which allow independent rewriting, as well as other tree-based models such as Yamada and Knight (2001) and Galley et al (2004).",[0],[1]
"Various state-of-the-art machine learning algorithms such as Maximum Entropy (Borthwick, 1999), AdaBoost (Carreras et al., 2002), Hidden Markov Models (Bikel et al,), Memory-based Based learning (Tjong Kim Sang, 2002b), have been used.","[32, 88]","[1, 1]"
Vieira and Poesio (2000) describe heuristics for processing definite descriptions in news text.,"[536, 0]","[1, 1]"
Wacholder et al (1997) use hand-written rules and knowledge bases to classify proper names into broad categories.,"[57, 59]","[1, 1]"
"We adopt a learning rate update rule from Koo et al (2010) where t is defined as 1/N, where N is the number of times we observed a consecutive dual value increase from iteration 1 to t.",[214],[1]
"We adopt the features from previous work by Han et al (2006), Tetreault and Chodorow (2008), and Rozovskaya et al (2011) for our system.","[64, 113]","[1, 1]"
"We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%).","[111, 50]","[1, 1]"
"We also compare with the CCG-based SRL presented in (Gildea and Hockenmaier, 2003) , which has a similar motivation as this paper, except they use the Combinatory Categorial Grammar formalism and the CCGBank syntactic Treebank which was converted from the Penn Tree bank.","[0, 8]","[1, 1]"
"We also compare with the multi parse system of (Toutanova et al, 2008) which uses a global joint model using multiple parse trees.",[94],[1]
"We also compare with two state-of-the-art methods that are used in sentiment prediction for conversations: (1) an SVM (RBF kernel) that is employed for identifying sentiment-bearing sentences (Hassan et al, 2010), and (dis) agreement detection (Yin et al, 2012) in on line debates; (2) a Linear CRF for (dis) agreement identification in broadcast conversations (Wang et al, 2011).","[145, 23]","[1, 1]"
We also experimented with the gold standard produced by Koeling et al (2005).,[30],[1]
"We also tried the word segmentation model of Dyer (2009) as implemented in the cdec decoder (Dyer et al, 2010), which learns word segmentation lattices from raw text in an unsupervised manner.","[121, 116]","[1, 1]"
"We also used additional annotation that has been developed to support higher-level analyses of meeting structure, in particular the ICSI Meeting Recorder Dialog act (MRDA) corpus (Shriberg et al., 2004).",[0],[1]
"We applied two mainstream Penn Treebank (PTB) phrase structure parsers: the Bikel parser, implementing Collins' parsing model (Bikel, 2004) and trained on PTB, and the reranking parser of (Charniak and Johnson, 2005) with the self-trained biomedical parsing model of (McClosky and Charniak, 2008).",[0],[1]
"We begin by outlining the general process of learning extraction patterns, similar to one presented by (Yangarber, 2003).",[62],[1]
"We begin by summarizing the model of Yamada and Knight (2001), which can be thought of as representing translation as an Alexander Calder mobile.",[0],[1]
"We compare our P-Mod algorithm against the t-test measure, which, of all standard measures, yields the best results in general-language collocation extraction studies (Evert and Krenn, 2001), and also against the widely used C-value, which aims at enhancing the common frequency of occurrence measure by making it sensitive to nested terms (Frantzi et al, 2000).",[100],[1]
"We compare our method with a state-of-the art approach SPG (Zhao et al, 2009), which is a statistical approach specially designed for PG.","[11, 84]","[1, 1]"
"We compare the performance of APS with that of two state-of-the-art segmenters: the Minimum Cut segmenter (Malioutov and Barzilay, 2006) and the Bayesian segmenter (Eisenstein and Barzilay, 2008).",[191],[1]
We compare this improved algorithm to our former algorithm (Schone and Jurafsky (2000)) as well as to Goldsmith's Linguistica (2000).,[98],[1]
"We compared our approach with the state-of-the-art confusion-network-based system (He et al, 2008) and achieved a significant absolute improvement of 1.23 BLEU points on the NIST 2005 Chinese-to-English test set and 0.93 BLEU point on the NIST 2008 Chinese-to-English test set.",[19],[1]
"We constructed a large, automatically annotated corpus by merging the output of Charniak's statistical parser (Charniak, 2000) with that of the IBM named entity recognition system Nominator (Wacholder et al,1997).",[59],[1]
"We could use other word-based dependency trees such as trees by the infinite PCFG model (Liang et al, 2007) and syntactic-head or semantic-head dependency trees in Nakazawa and Kurohashi (2012), although it is not our major focus.",[232],[1]
"We describe the Stanford entry to the BioNLP2011 shared task on biomolecular event extraction (Kim et al, 2011a).","[25, 3, 0]","[1, 1, 1]"
We did not compare our system with the joint model of Burkett and Klein (2008) because they reported the results on phrase structures.,"[128, 123]","[1, 1]"
We do not run self-training for POS tagging as it has been shown unuseful for this application (Clark et al 2003).,[121],[1]
"We employ 8 different MT metrics for identifying paraphrases across two different datasets the well-known Microsoft Research paraphrase corpus (MSRP) (Dolan et al, 2004) and the plagiarism detection corpus (PAN) from the 2010 Uncovering Plagiarism, Authorship and Social Software Misuse shared task (Potthast et al, 2010).",[11],[1]
"We follow a bottom-up chart generation approach (Kay, 1996) for production systems similar to (Varges, 2005).",[0],[1]
"We follow the CoNLL2011 scheme to select TRAIN, DEV and TEST datasets (Pradhan et al,2011).",[128],[1]
"We formulate our lexicon adaptation task using integer linear programming (ILP), which has been shown to bevery effective when solving problems with complex constraints (e.g., Roth and Yih (2004), Denis and Baldridge (2007)).","[0, 100]","[1, 1]"
"We found that the deletion of lead parts did not occur very often in our summary, unlike the case of Jing and McKeown (2000).",[123],[1]
"We have compared the performance of SVM with three other learning algorithms: (1) semantic scattering (Moldovan et al 2004), (2) decision trees (a C4.5 implementation), and (3) Naive Bayes.",[131],[1]
"We have evaluated our method using SemEval-2007 Task 07 (Coarse-grained English All-words Task) test set (Navigli et al, 2007).",[0],[1]
"We implemented our own decoder based on the algorithm described in (Ueffing et al, 2002).",[51],[1]
"We include in the table results from the pure transition-based parser of Zhang and Clark (2008) (row 'Z&C08 transition'), the dynamic-programming arc-standard parser of Huang and Sagae (2010) (row 'H&S10'), and graph based models including MSTParser (McDonald and Pereira, 2006), the baseline feature parser of Koo et al. (2008) (row 'K08 baeline'), and the two models of Koo and Collins (2010).",[8],[1]
"We intend to investigate any potential linkages between the word groups in the texts and other theories that provide pre-determined structures of text, such as Rhetorical Structure Theory (Marcu, 1997).",[0],[1]
"We investigated four individual approaches for the syntax-features, a regular-expression-based quasi-parser, a system based on Dekang Lin's Mini Par (Lin, 1993), a system based on the Collins parser (Collins, 1999), and one based on the CMU Link Grammar Parser (Sleator and Temperley, 1993), as well as a family of voting-based combination schemes.",[0],[1]
"We measured inter-annotator agreement with the Kappa statistic (Carletta, 1996) using the 1,391 items that two annotators scored in common.",[0],[1]
"We note that the best performing system (Chan et al, 2007b) of this task achieved a relatively high accuracy of 82.5%, highlighting the importance of having an appropriate level of sense granularity.",[19],[1]
We now turn to the concise integer LP formulation of Martins et al (2009).,"[50, 126]","[1, 1]"
"We participated in the BioNLP-ST 2011 (Kim et al, 2011a), and applied a graph matching-based approach (Liu et al, 2010) to tackling the Task 1 of the GE NIA event extraction (GE) task (Kim et al, 2011b), and the core task of the Epigenetics and Post-translational Modifications (EPI) task (Ohta et al, 2011), two main tasks of the BioNLP-ST 2011.","[15, 3, 21]","[1, 1, 1]"
"We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al, 2004) automatically extracted from tree banks, maximising the probability of a tree given an f-structure.",[29],[1]
"We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009).",[81],[1]
We propose SG-ITG that follows Wellington et al (2006)'s suggestion to model at most one gap.,"[46, 172]","[1, 1]"
"We ran the C & C parser using the normal-form model (we reproduced the numbers reported in Clark and Cur ran (2007)), and copied the results of the hybrid model from Clark and Curran (2007), since the hybrid model is not part of the public release.",[796],[1]
"We recommend mate-tools (Bjorkelund et al, 2009) and SuperSenseTagger (Ciaramita and Altun, 2006).","[208, 85]","[1, 1]"
"We report case-insensitive scores on version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al, 2002), and version 5 of TER (Snover et al, 2006).","[11, 7]","[1, 1]"
We reported the clustering results using the same clustering strategy as Hasegawa et al (2004) proposed.,[66],[1]
"We say a schema is a textual schema if it has been extracted from free text, such as the Nell (Carlson et al, 2010) and ReVerb (Fader et al, 2011) extracted databases.","[12, 13]","[1, 1]"
"We see promising improvements over an n-gram LM for a solid Joshua-based baseline system (Li et al, 2009).",[6],[1]
"We should keep in mind that (1) a tree bank PCFG is not state-of-the-art: its performance is mediocre compared to e.g. Bod (2003) or McClosky et al (2006), and (2) that our tree bank PCFG is binarized as in Klein and Manning (2005) to make results comparable.",[24],[1]
"We stand in a marked contrast to previous 'grafting' approaches which more or less rely on an ad-hoc collection of transformation rules to generate candidates (Riezler et al, 2003).","[136, 78]","[1, 1]"
We start with the model introduced by Carreras (2007).,[91],[1]
"We then cluster the simplified sentences withSimFinder (Hatzivassiloglou et al, 1999).",[170],[1]
"We use OpinionFinder (Wilson et al, 2005) which employs negative and positive polarity cues.","[44, 39]","[1, 1]"
"We use TnT (Brants, 2000), a second order Markov Model tagger.",[27],[1]
"We use a support vector machine (SVM) based chunker yamcha (Kudo and Matsumoto, 2001) for the chunking process.",[0],[1]
"We use the Tree Tagger (Schmid, 1994) for all POS tagging except for Arabic, where we use the tagger described in Diab et al.",[143],[1]
"We use the inference process introduced by (Punyakanok et al, 2004).",[9],[1]
"We use the maximum-entropy model proposed in Wong and Mooney (2006), which defines a conditional probability distribution over derivations given an observed NL sentence.",[117],[1]
"We use the same alignment data for the five language pairs Chinese/English, Romanian/English, Hindi/English, Spanish/English, and French/English (Wellington et al, 2006).","[64, 63]","[1, 1]"
"We use the standard splits of the data used in semi-supervised tagging experiments (e.g.Banko and Moore (2004)): sections 0-18 for training, 19-21 for development, and 22-24 for test.CCG-TUT.",[59],[1]
"We used YamCha (Kudo and Matsumoto, 2003) to detect named entities, and we trained it on the SemEval full-text training sets.","[10, 114]","[1, 1]"
"We used a feature set which included the current, next, and previous word; the previous two tags; various capitalization and other features of the word being tagged (the full feature set is described in (Collins 2002a)).",[42],[1]
"We used sparse feature templates that are equivalent to the PBMT set described in (Hopkins and May, 2011).",[131],[1]
"We used the Bikel Chinese head finder (Bikel and Chiang, 2000) and the Collins English head finder (Collins, 1999) to transform the gold constituency parses into gold dependency parses.",[44],[1]
We weigh each context f using point wise mutual information (Church and Hanks 1989).,[0],[1]
"We would like the parsing model to include long-range dependencies, but this introduces problems for generative parsing models similar to those described by Abney (1997) for attribute-value grammars.",[0],[1]
"We'd like to learn the number of paradigm classes from the data, but doing this would probably require extending adaptor grammars to incorporate the kind of adaptive state splitting found in the iHMM and iPCFG (Liang et al., 2007).","[232, 195]","[1, 1]"
"When Klein and Manning induce the parts-of-speech, they do so from a much larger corpus containing the full WSJ tree bank together with additional WSJ newswire (Klein and Manning,2002).",[15],[1]
"While (Yamada and Knight, 2002) represent syntactical information in the decoding process through a series of transformation operations, we operate directly at the phrase level.",[55],[1]
"While a similar result was obtained in Bod (2006), the absolute difference between unsupervised parsing and the treebank grammar was extremely small in Bod (2006): 1.8%, while the difference in table 5 is 7.2%, corresponding to 19.7% error reduction.",[40],[1]
"While early approaches focused on surface-level methods such as wrapper induction (Kushmerick et al, 1997), more recent work in this area includes Bayesian nonparametrics to select the number of rows in the database (Haghighi and Klein, 2010a).","[66, 142]","[1, 1]"
"While in lattice decoding, a translation path may skip some nodes as some hypothesis arcs may cross more than one backbone arc. Similar to the features in Rosti et al.(2007a), the features adopted by lattice-based model are arc posterior probability, language model probability, the number of null arcs, the number of hypothesis arcs possessing more than one non-null word and the number of all non-null words.",[126],[1]
"While template-based representations have been proposed for information merging in the past (Radev and McKeown, 1998), they considered only domain-specific scenarios.",[468],[1]
"While theoretically sound, this approach is computationally challenging both in practice (DeNero et al, 2008) and in theory (DeNero and Klein, 2008), may suffer from reference reachability problems (DeNero et al, 2006), and in the end may lead to inferior translation quality (Koehn et al, 2003).","[57, 19]","[1, 1]"
"While word senses have been studied extensively in lexical semantics, research has focused on word sense disambiguation, the task of disambiguating words in context given a predefined sense inventory (e.g., Agirre and Edmonds (2006)), and word sense induction, the task of learning sense inventories from text (e.g., Agirre and Soroa (2007)).",[22],[1]
"Within the ParGram project (Butt et al, 2002), Kim et al (2003) were able to directly port the argument optionality related rules from a Japanese grammar to Korean.",[21],[1]
Xiaofeng et al. (2004) or Strube and Müller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e.g. rewriting rule sets.,[8],[1]
"Xiong et al (2005) used a similar model to the BBN's model in (Bikel and Chiang, 2000), and augmented the model by semantic categorical information and heuristic rules.","[2, 13]","[1, 1]"
"Yarowsky (1994) notes that conceptual spelling correction is part of a closely related class of problems which include word sense disambiguation, word choice selection in machine translation, and accent and capitalization restoration.",[18],[1]
Zens and Ney (2003) [3] show that ITG constraints yield significantly better alignment coverage than the constraints used in IBM statistical machine translation models on both German-English (Verbmobil corpus) and French-English (Canadian Hansards corpus).,[187],[1]
"Zhou et al (2005) further systematically explored diverse lexical, syntactic and semantic features through support vector machines and achieved F- measure of 68.1 and 55.5 on the 5 relation types and the 24 relation subtypes in the ACE RDC 2003 corpus respectively.",[35],[1]
Zhou et al (2007) point out that both SPT and the convolution tree kernel are context-free.,[145],[1]
"a noisy-channel model which selects the most likely answer to a question (cf. (Echihabi and Marcu, 2003)).",[0],[1]
"a) Non-anaphoric detection modules b) Pronominal resolution module The data used for training as well as testing was provided CoNLL-2001 shared task (Pradhan et al, 2011), (Pradhan et al, 2007) organizers.",[128],[1]
k-best lists are extracted from the CRF trellis using the lazy enumeration algorithm of Huang and Chiang (2005).,[177],[1]
"our model incorporates the text-level of anaphora resolution, a shortcoming of the original SG approach that has recently been removed (Lappin and Leass, 1994), but still is a source of lots of problems.",[0],[1]
"reported accuracies of 93% and 93.74% on CTB-I (Xue et al, 2002) (100K words) and CTB 5.0 (500K words), respectively, each using a Maximum Entropy approach.",[5],[1]
see Klein and Manning (2003c) for details.,"[65, 141]","[1, 1]"
"task Corpus Sentences Tokens En Zh/Ar MT05 1082 35k 33k training 1M 23.7M 22.8M tune (MT06) 1797 55k 49k baselines: hypergraph-based MERT (Kumar et al., 2009), k-best variants of MIRA (Crammer et al., 2006; Chiang et al., 2009), PRO (Hopkins and May, 2011), and RAMPION (Gimpel and Smith, 2012).",[14],[1]
tree-to-tree translation model based on tree sequence alignment (Zhang et al 2008a) without losing of generality to most syntactic tree based models.,"[0, 11, 28, 30]","[1, 1, 1, 1]"
