Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","'8','14','2','107','25','48','12','108'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""14"" ssid=""7"">Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al., 2001).</S><S sid=""2"" ssid=""2"">The problem with using the predominant, or first sense heuristic, aside from the fact that it does not take surrounding context into account, is that it assumes some quantity of handtagged data.</S><S sid=""107"" ssid=""5"">To disambiguate senses a system should take context into account.</S><S sid=""25"" ssid=""18"">However, the most accurate WSD systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (Yarowsky and Florian, 2002) available.</S><S sid=""48"" ssid=""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid=""12"" ssid=""5"">The figure distinguishes systems which make use of hand-tagged data (using HTD) such as SemCor, from those that do not (without HTD).</S><S sid=""108"" ssid=""6"">However, it is important to know the performance of this heuristic for any systems that use it.</S>",
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","'15','3','154','17','25','180','22'","<S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""3"" ssid=""3"">Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration.</S><S sid=""154"" ssid=""2"">In contrast, our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one, and because handtagged data is not always available.</S><S sid=""17"" ssid=""10"">There are words where the first sense in WordNet is counter-intuitive, because of the size of the corpus, and because where the frequency data does not indicate a first sense, the ordering is arbitrary.</S><S sid=""25"" ssid=""18"">However, the most accurate WSD systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (Yarowsky and Florian, 2002) available.</S><S sid=""180"" ssid=""3"">The automatically acquired predominant senses were evaluated against the hand-tagged resources SemCor and the SENSEVAL-2 English all-words task giving us a WSD precision of 64% on an all-nouns task.</S><S sid=""22"" ssid=""15"">More importantly, when working within a specific domain one would wish to tune the first sense heuristic to the domain at hand.</S>",
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","'64','49','133','137','29','109','80','79'","<S sid=""64"" ssid=""20"">We briefly summarise the two measures here; for a more detailed summary see (Patwardhan et al., 2003).</S><S sid=""49"" ssid=""5"">Let be the ordered set of the top scoring neighbours of from the thesaurus with associated distributional similarity scores The thesaurus was acquired using the method described by Lin (1998).</S><S sid=""133"" ssid=""10"">We acquired thesauruses for these corpora using the procedure described in section 2.1.</S><S sid=""137"" ssid=""14"">Additionally, we evaluated our method quantitatively using the Subject Field Codes (SFC) resource (Magnini and Cavagli`a, 2000) which annotates WordNet synsets with domain labels.</S><S sid=""29"" ssid=""22"">We discuss our method in the following section.</S><S sid=""109"" ssid=""7"">We generated a thesaurus entry for all polysemous nouns in WordNet as described in section 2.1 above.</S><S sid=""80"" ssid=""9"">All the results shown here are those with the size of thesaurus entries ( ) set to 50.</S><S sid=""79"" ssid=""8"">3 The experimental results reported here are obtained using IC counts from the BNC corpus.</S>",
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"'15','165','0','41'","<S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""165"" ssid=""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid=""0"">Finding Predominant Word Senses in Untagged Text</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S>",
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","'153','15','0','175','68','152'","<S sid=""153"" ssid=""1"">Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""0"">Finding Predominant Word Senses in Untagged Text</S><S sid=""175"" ssid=""23"">We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S><S sid=""68"" ssid=""24"">We are of course able to apply the method to other versions of WordNet. synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation.</S><S sid=""152"" ssid=""29"">We see that both domains have a similarly high percentage of factotum (domain independent) labels, but as we would expect, the other peaks correspond to the economy label for the FINANCE corpus, and the sports label for the SPORTS corpus. inant senses for 38 polysemous words ranked using the SPORTS and FINANCE corpus.</S>",
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","'112','102','116','74','165','1','15'","<S sid=""112"" ssid=""10"">We compare results using the first sense listed in SemCor, and the first sense according to the SENSEVAL-2 English all-words test data itself.</S><S sid=""102"" ssid=""31"">We test this below on the SENSEVAL-2 English all-words data.</S><S sid=""116"" ssid=""14"">The performance of the predominant sense provided in the SENSEVAL-2 test data provides an upper bound for this task.</S><S sid=""74"" ssid=""3"">Nevertheless, since many systems performed well on the English all-words task for SENSEVAL-2 by using the frequency information in SemCor this is a reasonable approach for evaluation.</S><S sid=""165"" ssid=""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid=""1"" ssid=""1"">word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S>",
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","'165','15','31','152','95','77','3'","<S sid=""165"" ssid=""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""31"" ssid=""24"">In section 5 we present results of the method on two domain specific sections of the Reuters corpus for a sample of words.</S><S sid=""152"" ssid=""29"">We see that both domains have a similarly high percentage of factotum (domain independent) labels, but as we would expect, the other peaks correspond to the economy label for the FINANCE corpus, and the sports label for the SPORTS corpus. inant senses for 38 polysemous words ranked using the SPORTS and FINANCE corpus.</S><S sid=""95"" ssid=""24"">Since SemCor is derived from the Brown corpus, which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6, the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid=""77"" ssid=""6"">We experimented with counts obtained from the BNC and the Brown corpus.</S><S sid=""3"" ssid=""3"">Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration.</S>",
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","'48','52','46','41','45','145'","<S sid=""48"" ssid=""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid=""52"" ssid=""8"">For each sense of ( ) we obtain a ranking score by summing over the of each neighbour ( ) multiplied by a weight.</S><S sid=""46"" ssid=""2"">This provides the nearest neighbours to each target word, along with the distributional similarity score between the target word and its neighbour.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""45"" ssid=""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid=""145"" ssid=""22"">It is not always intuitively clear which of the senses to expect as predominant sense for either a particular domain or for the BNC, but the first senses of words like division and goal shift towards the more specific senses (league and score respectively).</S>",
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","'79','63','83','188','47','80','179','76'","<S sid=""79"" ssid=""8"">3 The experimental results reported here are obtained using IC counts from the BNC corpus.</S><S sid=""63"" ssid=""19"">We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.</S><S sid=""83"" ssid=""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid=""188"" ssid=""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al., 2004).</S><S sid=""47"" ssid=""3"">We then use the WordNet similarity package (Patwardhan and Pedersen, 2003) to give us a semantic similarity measure (hereafter referred to as the WordNet similarity measure) to weight the contribution that each neighbour makes to the various senses of the target word.</S><S sid=""80"" ssid=""9"">All the results shown here are those with the size of thesaurus entries ( ) set to 50.</S><S sid=""179"" ssid=""2"">We use an automatically acquired thesaurus and a WordNet Similarity measure.</S><S sid=""76"" ssid=""5"">The jcn measure uses corpus data for the calculation of IC.</S>",
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","'41','175','15'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""175"" ssid=""23"">We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S>",
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","'48','165','188','49'","<S sid=""48"" ssid=""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid=""165"" ssid=""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid=""188"" ssid=""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al., 2004).</S><S sid=""49"" ssid=""5"">Let be the ordered set of the top scoring neighbours of from the thesaurus with associated distributional similarity scores The thesaurus was acquired using the method described by Lin (1998).</S>",
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","'168','133','74','29','175'","<S sid=""168"" ssid=""16"">They evaluate using the lin measure described above in section 2.2 to determine the precision and recall of these discovered classes with respect to WordNet synsets.</S><S sid=""133"" ssid=""10"">We acquired thesauruses for these corpora using the procedure described in section 2.1.</S><S sid=""74"" ssid=""3"">Nevertheless, since many systems performed well on the English all-words task for SENSEVAL-2 by using the frequency information in SemCor this is a reasonable approach for evaluation.</S><S sid=""29"" ssid=""22"">We discuss our method in the following section.</S><S sid=""175"" ssid=""23"">We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.</S>",
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","'1','13','8','161','84','74','85','86'","<S sid=""1"" ssid=""1"">word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S><S sid=""13"" ssid=""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""161"" ssid=""9"">Our approach is complementary to this.</S><S sid=""84"" ssid=""13"">The random baseline for choosing the predominant sense over all these words ( ) is 32%.</S><S sid=""74"" ssid=""3"">Nevertheless, since many systems performed well on the English all-words task for SENSEVAL-2 by using the frequency information in SemCor this is a reasonable approach for evaluation.</S><S sid=""85"" ssid=""14"">Both WordNet similarity measures beat this baseline.</S><S sid=""86"" ssid=""15"">The random baseline for ( ) is 24%.</S>",
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","'89','105','174','22','103','113','155','166'","<S sid=""89"" ssid=""18"">Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the IC files.</S><S sid=""105"" ssid=""3"">We use an allwords task because the predominant senses will reflect the sense distributions of all nouns within the documents, rather than a lexical sample task, where the target words are manually determined and the results will depend on the skew of the words in the sample.</S><S sid=""174"" ssid=""22"">We have restricted ourselves to nouns in this work, since this PoS is perhaps most affected by domain.</S><S sid=""22"" ssid=""15"">More importantly, when working within a specific domain one would wish to tune the first sense heuristic to the domain at hand.</S><S sid=""103"" ssid=""1"">In order to see how well the automatically acquired predominant sense performs on a WSD task from which the WordNet sense ordering has not been taken, we use the SENSEVAL-2 all-words data (Palmer et al., 2001).</S><S sid=""113"" ssid=""11"">For the latter, we only take a first-sense where there is more than one occurrence of the noun in the test data and one sense has occurred more times than any of the others.</S><S sid=""155"" ssid=""3"">A major benefit of our work, rather than reliance on hand-tagged training data such as SemCor, is that this method permits us to produce predominant senses for the domain and text type required.</S><S sid=""166"" ssid=""14"">There has been some related work on using automatic thesauruses for discovering word senses from corpora Pantel and Lin (2002).</S>",
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","'188','8','163','15','82','176'","<S sid=""188"" ssid=""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al., 2004).</S><S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""163"" ssid=""11"">Lapata and Brew (2004) have recently also highlighted the importance of a good prior in WSD.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""82"" ssid=""11"">We also calculate the WSD accuracy that would be obtained on SemCor, when using our first sense in all contexts ( ).</S><S sid=""176"" ssid=""24"">The lesk measure can be used when ranking adjectives, and adverbs as well as nouns and verbs (which can also be ranked using jcn).</S>",
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","'8','25','40','153','80','79'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""25"" ssid=""18"">However, the most accurate WSD systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (Yarowsky and Florian, 2002) available.</S><S sid=""40"" ssid=""33"">This is because there will be more relational data for the more prevalent senses compared to the less frequent senses.</S><S sid=""153"" ssid=""1"">Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S><S sid=""80"" ssid=""9"">All the results shown here are those with the size of thesaurus entries ( ) set to 50.</S><S sid=""79"" ssid=""8"">3 The experimental results reported here are obtained using IC counts from the BNC corpus.</S>",
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","'8','25','15','13','153','40','82'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""25"" ssid=""18"">However, the most accurate WSD systems are those which require manually sense tagged data in the first place, and their accuracy depends on the quantity of training examples (Yarowsky and Florian, 2002) available.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""13"" ssid=""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid=""153"" ssid=""1"">Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S><S sid=""40"" ssid=""33"">This is because there will be more relational data for the more prevalent senses compared to the less frequent senses.</S><S sid=""82"" ssid=""11"">We also calculate the WSD accuracy that would be obtained on SemCor, when using our first sense in all contexts ( ).</S>",
