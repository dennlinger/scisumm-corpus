Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,A97-1014,E99-1016,0,"Skut et al, 1997",0,"This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","'168','12','137','38','72','20'","<S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""12"" ssid=""2"">Realworld texts annotated with different strata of linguistic information can be used for grammar induction.</S><S sid=""137"" ssid=""18"">The following commands are available: The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus.</S><S sid=""38"" ssid=""28"">Due to the frequency of discontinuous constituents in non-configurational languages, the filler-trace mechanism would be used very often, yielding syntactic trees fairly different from the underlying predicate-argument structures.</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S><S sid=""20"" ssid=""10"">Data-drivenness: The scheme must provide representational means for all phenomena occurring in texts.</S>",['method_citation']
2,A97-1014,E99-1016,0,"Skut et al, 1997",0,"For our experiments, we use the NEGRA corpus (Skut et al, 1997)","For our experiments, we use the NEGRA corpus (Skut et al, 1997)","'168','144','148','141','72'","<S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S><S sid=""148"" ssid=""29"">For a phrase Q with children of type T&#8222;..., Ta and grammatical functions G&#8222;...,GA., we use the lexical probabilities and the contextual (trigram) probabilities The lexical and contextual probabilities are determined separately for each type of phrase.</S><S sid=""141"" ssid=""22"">The corpus is stored in a SQL database.</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S>","['method_citation','results_citation']"
3,A97-1014,E12-1047,0,"Skut et al, 1997",0,"As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 Frequenc y Parsing complexity head-driven optimal head-driven Figure 6: The distribution of parsing complexity among productions in Markovized, head-driven grammars read off from NEGRA-25","As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training","'140','99','6','145','149','62','171'","<S sid=""140"" ssid=""21"">For the implementation, we used Tcl/Tk Version 4.1.</S><S sid=""99"" ssid=""12"">Because of the intended theory-independence of the scheme, we annotate only the common minimum.</S><S sid=""6"" ssid=""3"">In section 2, we examine the appropriateness of existing annotation schemes.</S><S sid=""145"" ssid=""26"">This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).</S><S sid=""149"" ssid=""30"">During annotation, the highest rated grammatical function labels Gi are calculated using the Viterbi algorithm and assigned to the structure, i.e., we calculate argma.x11 PQ (Ti 1Z-1, Ti.-2) PQ (Gi ITi).</S><S sid=""62"" ssid=""7"">2.</S><S sid=""171"" ssid=""13"">Partial automation included in the current version significantly reduces the manna.1 effort.</S>",['method_citation']
5,A97-1014,I05-6010,0,1997,0,According to Skut et al (1997) tree banks have to meet the following requirements: 1,According to Skut et al (1997) tree banks have to meet the following requirements: 1,"'15','53','2','74','7','8','104'","<S sid=""15"" ssid=""5"">Existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: Grammatical phenomena are to be described rather than explained.</S><S sid=""53"" ssid=""43"">A tree meeting these requirements is given below: Adv V NP NP V CPL NP V damn wird ihn Anna erkennen, dais er 'vein!</S><S sid=""2"" ssid=""2"">Since the requirements for such a formalism differ from those posited for configurational languages, several features have been added, influencing the architecture of the scheme.</S><S sid=""74"" ssid=""19"">During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.</S><S sid=""7"" ssid=""4"">On the basis of these considerations, we formulate several additional requirements.</S><S sid=""8"" ssid=""5"">A formalism complying with these requirements is described in section 3.</S><S sid=""104"" ssid=""17"">The head of the phrase can be determined in a similar way according to theory-specific assumptions.</S>","['hypothesis_citation','method_citation']"
7,A97-1014,C10-1061,0,"Skut et al, 1997",0,"In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997) .Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997). Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","'47','111','25','55','24','39','168'","<S sid=""47"" ssid=""37"">Argument structure can be represented in terms of unordered trees (with crossing branches).</S><S sid=""111"" ssid=""24"">If the scope of such a word does not directly correspond to a tree node, the word is attached to the lowest node dominating all subconstituents appearing in its scope.</S><S sid=""25"" ssid=""15"">The underlying argument SirlteilITC is not represented directly, but can be recovered from the tree and trace-filler annotations.</S><S sid=""55"" ssid=""45"">A uniform representation of local and non-local dependencies makes the structure more transparent'.</S><S sid=""24"" ssid=""14"">The typical treebank architecture is as follows: Structures: A context-free backbone is augmented with trace-filler representations of non-local dependencies.</S><S sid=""39"" ssid=""29"">Consider the German sentence (1) daran wird ihn Anna erkennen, &amp;di er weint at-it will him Anna recognise that he cries 'Anna will recognise him at his cry' A sample constituent structure is given below: The fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.</S><S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S>","['implication_citation','method_citation']"
8,A97-1014,C10-1061,0,"Skut et al, 1997",0,"Our data source is the German NeGra tree bank (Skut et al, 1997)","Our data source is the German NeGra tree bank (Skut et al, 1997)","'168','20','13','166','11','25','79','142'","<S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""20"" ssid=""10"">Data-drivenness: The scheme must provide representational means for all phenomena occurring in texts.</S><S sid=""13"" ssid=""3"">The data-drivenness of this approach presents a clear advantage over the traditional, idealised notion of competence grammar.</S><S sid=""166"" ssid=""8"">Syntactically annotated corpora of German have been missing until now.</S><S sid=""11"" ssid=""1"">Combining raw language data with linguistic information offers a promising basis for the development of new efficient and robust NLP methods.</S><S sid=""25"" ssid=""15"">The underlying argument SirlteilITC is not represented directly, but can be recovered from the tree and trace-filler annotations.</S><S sid=""79"" ssid=""24"">PM stands for morphological particle, a label for German infinitival Z7t and superlative am.</S><S sid=""142"" ssid=""23"">The degree of automation increases with the amount of data available.</S>",['method_citation']
9,A97-1014,P05-1039,0,"Skut et al, 1997",0,"The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","'168','151','144','141','167','72','137'","<S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""151"" ssid=""32"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S><S sid=""141"" ssid=""22"">The corpus is stored in a SQL database.</S><S sid=""167"" ssid=""9"">In the second phase of the project Verbmobil a. treebank for :30,000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S><S sid=""137"" ssid=""18"">The following commands are available: The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus.</S>","['method_citation','results_citation']"
10,A97-1014,P03-1013,0,"Skut et al, 1997",0,"The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","'4','166','168','31','151','72'","<S sid=""4"" ssid=""1"">The work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.</S><S sid=""166"" ssid=""8"">Syntactically annotated corpora of German have been missing until now.</S><S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""31"" ssid=""21"">Due to the substantial differences between existing models of constituent structure, the question arises of how the theory independencf requirement, can be satisfied.</S><S sid=""151"" ssid=""32"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S>","['method_citation','results_citation']"
11,A97-1014,P03-1013,0,"Skut et al, 1997",0,"The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","'160','174','15','45','127','22'","<S sid=""160"" ssid=""2"">These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.</S><S sid=""174"" ssid=""2"">We also wish to thank Robert MacIntyre and Ann Taylor for valuable discussions on the Penn Treebank annotation.</S><S sid=""15"" ssid=""5"">Existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: Grammatical phenomena are to be described rather than explained.</S><S sid=""45"" ssid=""35"">(McCawley, 1987), (Dowty, 1989), (Reape, 1993), (Kathol and Pollard, 1995).</S><S sid=""127"" ssid=""8"">As the need for certain functionalities becomes obvious with growing annotation experience, we have decided to implement the tool in two stages.</S><S sid=""22"" ssid=""12"">(Marcus et. al., 1994), (Sampson, 1995), (Black et. al.</S>",['method_citation']
13,A97-1014,W04-1505,0,"Skut et al, 1997",0,"German is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA an notation has been conceived to be quite at (Skut et al, 1997)","German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at (Skut et al, 1997)","'121','41','48','40','166','163','109'","<S sid=""121"" ssid=""2"">In order to make the annotation process more efficient, extra effort has been put. into the development of an annotation tool.</S><S sid=""41"" ssid=""31"">Apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: Finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which has proved tedious.</S><S sid=""48"" ssid=""38"">In order to reduce their ambiguity potential, rather simple, 'flat' trees should be employed, while more information can be expressed by a rich system of function labels.</S><S sid=""40"" ssid=""30"">This hybrid representation makes the structure less transparent, and therefore more difficult to annotate.</S><S sid=""166"" ssid=""8"">Syntactically annotated corpora of German have been missing until now.</S><S sid=""163"" ssid=""5"">In general, the resulting interpreted data also are closer to semantic annotation and more neutral with respect to particular syntactic theories.</S><S sid=""109"" ssid=""22"">In addition, we have adopted a simple convention for those cases in which context information is insufficient, for total disambiguation: the highest possible attachment, site is chosen.</S>",['method_citation']
14,A97-1014,C04-1074,0,"Skut et al, 1997",0,"The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","'168','14','166','39','137'","<S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""14"" ssid=""4"">Corpora annotated with syntactic structures are commonly referred to as trctbank.5.</S><S sid=""166"" ssid=""8"">Syntactically annotated corpora of German have been missing until now.</S><S sid=""39"" ssid=""29"">Consider the German sentence (1) daran wird ihn Anna erkennen, &amp;di er weint at-it will him Anna recognise that he cries 'Anna will recognise him at his cry' A sample constituent structure is given below: The fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.</S><S sid=""137"" ssid=""18"">The following commands are available: The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus.</S>",['method_citation']
16,A97-1014,P11-2067,0,"Skut et al, 1997",0,"CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","'151','137','168','141','51','44','72'","<S sid=""151"" ssid=""32"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S sid=""137"" ssid=""18"">The following commands are available: The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus.</S><S sid=""168"" ssid=""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid=""141"" ssid=""22"">The corpus is stored in a SQL database.</S><S sid=""51"" ssid=""41"">This requirement speaks against the traditional sort of dependency trees, in which heads a,re represented as non-terminal nodes, cf.</S><S sid=""44"" ssid=""34"">This assumption underlies a growing number of recent syntactic theories which give up the context-free constituent backbone, cf.</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S>","['method_citation','results_citation']"
17,A97-1014,W08-1007,0,"Skut et al, 1997",0,"Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negratreebank (Skut et al, 1997) reports that lexicaliza tion of PCFGs decrease the parsing accuracy when parsing Negra? s flat constituent structures","Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures","'156','24','48'","<S sid=""156"" ssid=""37"">Accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.</S><S sid=""24"" ssid=""14"">The typical treebank architecture is as follows: Structures: A context-free backbone is augmented with trace-filler representations of non-local dependencies.</S><S sid=""48"" ssid=""38"">In order to reduce their ambiguity potential, rather simple, 'flat' trees should be employed, while more information can be expressed by a rich system of function labels.</S>","['method_citation','results_citation']"
19,A97-1014,D07-1066,0,"Skut et al, 1997",0,"A comparison of unlexicalised PCFG parsing (Ku ?bler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","A comparison of unlexicalised PCFG parsing (Kubler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","'119','149','160'","<S sid=""119"" ssid=""32"">Structure-sharing is expressed using secondary links.</S><S sid=""149"" ssid=""30"">During annotation, the highest rated grammatical function labels Gi are calculated using the Viterbi algorithm and assigned to the structure, i.e., we calculate argma.x11 PQ (Ti 1Z-1, Ti.-2) PQ (Gi ITi).</S><S sid=""160"" ssid=""2"">These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.</S>",['method_citation']
