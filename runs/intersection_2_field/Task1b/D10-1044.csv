Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,D10-1044,P11-2074,0,"Foster et al, 2010",0,"Another popular task in SMT is domain adaptation (Foster et al, 2010)","Another popular task in SMT is domain adaptation (Foster et al, 2010)","'32','1','10','14','36','34','0','4','24'","<S sid=""32"" ssid=""29"">This is a straightforward technique that is arguably better suited to the adaptation task than the standard method of treating representative IN sentences as queries, then pooling the match results.</S><S sid=""1"" ssid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S sid=""10"" ssid=""7"">This is a standard adaptation problem for SMT.</S><S sid=""14"" ssid=""11"">There is a fairly large body of work on SMT adaptation.</S><S sid=""36"" ssid=""33"">Section 5 covers relevant previous work on SMT adaptation, and section 6 concludes.</S><S sid=""34"" ssid=""31"">Section 2 describes our baseline techniques for SMT adaptation, and section 3 describes the instance-weighting approach.</S><S sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S><S sid=""4"" ssid=""1"">Domain adaptation is a common concern when optimizing empirical NLP applications.</S><S sid=""24"" ssid=""21"">Sentence pairs are the natural instances for SMT, but sentences often contain a mix of domain-specific and general language.</S>",['method_citation']
2,D10-1044,P12-1048,0,"Foster et al, 2010",0,"In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","'95','144','68','26','54','152','2','96','94'","<S sid=""95"" ssid=""32"">Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models), and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples, with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set.</S><S sid=""144"" ssid=""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid=""68"" ssid=""5"">First, we learn weights on individual phrase pairs rather than sentences.</S><S sid=""26"" ssid=""23"">Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009), who weight sentences according to sub-corpus and genre membership.</S><S sid=""54"" ssid=""18"">However, we note that the final conditional estimates p(s|t) from a given phrase table maximize the likelihood of joint empirical phrase pair counts over a word-aligned corpus.</S><S sid=""152"" ssid=""9"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S><S sid=""2"" ssid=""2"">This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure.</S><S sid=""96"" ssid=""33"">We used it to score all phrase pairs in the OUT table, in order to provide a feature for the instance-weighting model.</S><S sid=""94"" ssid=""31"">In addition to using the simple features directly, we also trained an SVM classifier with these features to distinguish between IN and OUT phrase pairs.</S>","['method_citation','results_citation']"
3,D10-1044,D12-1129,0,"Foster et al., 2010",0,"Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010) .Research in Word Sense Disambiguation (Navigli, 2009, WSD), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now","Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010)","'0','46','7','9','4','105','5','142'","<S sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S><S sid=""46"" ssid=""10"">This has the potential drawback of increasing the number of features, which can make MERT less stable (Foster and Kuhn, 2009).</S><S sid=""7"" ssid=""4"">For developers of Statistical Machine Translation (SMT) systems, an additional complication is the heterogeneous nature of SMT components (word-alignment model, language model, translation model, etc.</S><S sid=""9"" ssid=""6"">In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material&#8212;though adequate for reasonable performance&#8212;is also available.</S><S sid=""4"" ssid=""1"">Domain adaptation is a common concern when optimizing empirical NLP applications.</S><S sid=""105"" ssid=""9"">Compared to the EMEA/EP setting, the two domains in the NIST setting are less homogeneous and more similar to each other; there is also considerably more IN text available.</S><S sid=""5"" ssid=""2"">Even when there is training data available in the domain of interest, there is often additional data from other domains that could in principle be used to improve performance.</S><S sid=""142"" ssid=""11"">There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007).</S>",['method_citation']
4,D10-1044,P14-2093,0,2010,0,"Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","'62','24','1','89','25','143','26','9'","<S sid=""62"" ssid=""26"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S sid=""24"" ssid=""21"">Sentence pairs are the natural instances for SMT, but sentences often contain a mix of domain-specific and general language.</S><S sid=""1"" ssid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S sid=""89"" ssid=""26"">We used 22 features for the logistic weighting model, divided into two groups: one intended to reflect the degree to which a phrase pair belongs to general language, and one intended to capture similarity to the IN domain.</S><S sid=""25"" ssid=""22"">For instance, the sentence Similar improvements in haemoglobin levels were reported in the scientific literature for other epoetins would likely be considered domain-specific despite the presence of general phrases like were reported in.</S><S sid=""143"" ssid=""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008).</S><S sid=""26"" ssid=""23"">Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009), who weight sentences according to sub-corpus and genre membership.</S><S sid=""9"" ssid=""6"">In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material&#8212;though adequate for reasonable performance&#8212;is also available.</S>",['method_citation']
5,D10-1044,E12-1055,0,2010,0,"However, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .Our main technical contributions are as fol lows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. Also, we independently perform perplexity minimization for all four features of the standard SMTtranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)","Our main technical contributions are as follows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation","'62','50','71','79','34','59'","<S sid=""62"" ssid=""26"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S sid=""50"" ssid=""14"">Linear weights are difficult to incorporate into the standard MERT procedure because they are &#8220;hidden&#8221; within a top-level probability that represents the linear combination.1 Following previous work (Foster and Kuhn, 2007), we circumvent this problem by choosing weights to optimize corpus loglikelihood, which is roughly speaking the training criterion used by the LM and TM themselves.</S><S sid=""71"" ssid=""8"">Finally, we incorporate the instance-weighting model into a general linear combination, and learn weights and mixing parameters simultaneously. where c&#955;(s, t) is a modified count for pair (s, t) in OUT, u(s|t) is a prior distribution, and y is a prior weight.</S><S sid=""79"" ssid=""16"">This combination generalizes (2) and (3): we use either at = a to obtain a fixed-weight linear combination, or at = cI(t)/(cI(t) + 0) to obtain a MAP combination.</S><S sid=""34"" ssid=""31"">Section 2 describes our baseline techniques for SMT adaptation, and section 3 describes the instance-weighting approach.</S><S sid=""59"" ssid=""23"">To set &#946;, we used the same criterion as for &#945;, over a dev corpus: The MAP combination was used for TM probabilities only, in part due to a technical difficulty in formulating coherent counts when using standard LM smoothing techniques (Kneser and Ney, 1995).3 Motivated by information retrieval, a number of approaches choose &#8220;relevant&#8221; sentence pairs from OUT by matching individual source sentences from IN (Hildebrand et al., 2005; L&#168;u et al., 2007), or individual target hypotheses (Zhao et al., 2004).</S>",['method_citation']
6,D10-1044,E12-1055,0,2010,0,"Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) ex tend this approach by weighting individual phrase pairs","Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) extend this approach by weighting individual phrase pairs","'1','144','151','68','26','65','152','67'","<S sid=""1"" ssid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S sid=""144"" ssid=""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid=""151"" ssid=""8"">In future work we plan to try this approach with more competitive SMT systems, and to extend instance weighting to other standard SMT components such as the LM, lexical phrase weights, and lexicalized distortion.</S><S sid=""68"" ssid=""5"">First, we learn weights on individual phrase pairs rather than sentences.</S><S sid=""26"" ssid=""23"">Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009), who weight sentences according to sub-corpus and genre membership.</S><S sid=""65"" ssid=""2"">Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities.</S><S sid=""152"" ssid=""9"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S><S sid=""67"" ssid=""4"">We extend the Matsoukas et al approach in several ways.</S>",['method_citation']
7,D10-1044,E12-1055,0,2010,0,"These more fine-grained methods need not be seen as alternatives to coarse-grained ones. Foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model","Foster et al (2010) combine the two, applying linear interpolation to combine the instance weighted out-of-domain model with an in-domain model","'144','133','71'","<S sid=""144"" ssid=""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid=""133"" ssid=""2"">It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S><S sid=""71"" ssid=""8"">Finally, we incorporate the instance-weighting model into a general linear combination, and learn weights and mixing parameters simultaneously. where c&#955;(s, t) is a modified count for pair (s, t) in OUT, u(s|t) is a prior distribution, and y is a prior weight.</S>","['method_citation','results_citation']"
8,D10-1044,E12-1055,0,Foster et al 2010,0,Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN) Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN); Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),"'106','49','5','100','52','9','55','133'","<S sid=""106"" ssid=""10"">The corpora for both settings are summarized in table 1.</S><S sid=""49"" ssid=""13"">This leads to a linear combination of domain-specific probabilities, with weights in [0, 1], normalized to sum to 1.</S><S sid=""5"" ssid=""2"">Even when there is training data available in the domain of interest, there is often additional data from other domains that could in principle be used to improve performance.</S><S sid=""100"" ssid=""4"">Figure 1 shows sample sentences from these domains, which are widely divergent.</S><S sid=""52"" ssid=""16"">It is not immediately obvious how to formulate an equivalent to equation (1) for an adapted TM, because there is no well-defined objective for learning TMs from parallel corpora.</S><S sid=""9"" ssid=""6"">In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material&#8212;though adequate for reasonable performance&#8212;is also available.</S><S sid=""55"" ssid=""19"">This suggests a direct parallel to (1): where &#732;p(s, t) is a joint empirical distribution extracted from the IN dev set using the standard procedure.2 An alternative form of linear combination is a maximum a posteriori (MAP) combination (Bacchiani et al., 2004).</S><S sid=""133"" ssid=""2"">It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S>",['method_citation']
9,D10-1044,E12-1055,0,Foster et al 2010,0,"We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 We demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted MLE training, but are of little prominence in domain adaptation research",We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translation models,"'7','40','0','97','62','44'","<S sid=""7"" ssid=""4"">For developers of Statistical Machine Translation (SMT) systems, an additional complication is the heterogeneous nature of SMT components (word-alignment model, language model, translation model, etc.</S><S sid=""40"" ssid=""4"">We focus here instead on adapting the two most important features: the language model (LM), which estimates the probability p(wIh) of a target word w following an ngram h; and the translation models (TM) p(slt) and p(t1s), which give the probability of source phrase s translating to target phrase t, and vice versa.</S><S sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S><S sid=""97"" ssid=""1"">We carried out translation experiments in two different settings.</S><S sid=""62"" ssid=""26"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S sid=""44"" ssid=""8"">When OUT is large and distinct, its contribution can be controlled by training separate IN and OUT models, and weighting their combination.</S>",['method_citation']
10,D10-1044,P12-1099,0,"Foster et al, 2010",0,"In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) 940 as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","'28','94','144','3','126','150'","<S sid=""28"" ssid=""25"">We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.</S><S sid=""94"" ssid=""31"">In addition to using the simple features directly, we also trained an SVM classifier with these features to distinguish between IN and OUT phrase pairs.</S><S sid=""144"" ssid=""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid=""3"" ssid=""3"">We incorporate instance weighting into a mixture-model framework, and find that it yields consistent improvements over a wide range of baselines.</S><S sid=""126"" ssid=""30"">The 4th block contains instance-weighting models trained on all features, used within a MAP TM combination, and with a linear LM mixture.</S><S sid=""150"" ssid=""7"">In both cases, the instanceweighting approach improved over a wide range of baselines, giving gains of over 2 BLEU points over the best non-adapted baseline, and gains of between 0.6 and 1.8 over an equivalent mixture model (with an identical training procedure but without instance weighting).</S>",['method_citation']
11,D10-1044,P12-1099,0,2010,0,m ?mpm (e? |f?) Our technique for setting? m is similar to that outlined in Foster et al (2010),Our technique for setting ? m is similar to that outlined in Foster et al (2010),"'18','105','34','32','17','30','23'","<S sid=""18"" ssid=""15"">This is less effective in our setting, where IN and OUT are disparate.</S><S sid=""105"" ssid=""9"">Compared to the EMEA/EP setting, the two domains in the NIST setting are less homogeneous and more similar to each other; there is also considerably more IN text available.</S><S sid=""34"" ssid=""31"">Section 2 describes our baseline techniques for SMT adaptation, and section 3 describes the instance-weighting approach.</S><S sid=""32"" ssid=""29"">This is a straightforward technique that is arguably better suited to the adaptation task than the standard method of treating representative IN sentences as queries, then pooling the match results.</S><S sid=""17"" ssid=""14"">Previous approaches have tried to find examples that are similar to the target domain.</S><S sid=""30"" ssid=""27"">A similar maximumlikelihood approach was used by Foster and Kuhn (2007), but for language models only.</S><S sid=""23"" ssid=""20"">Our second contribution is to apply instance weighting at the level of phrase pairs.</S>","['method_citation','results_citation']"
12,D10-1044,P12-1099,0,"Foster et al., 2010",0,"m ?mpm (e? |f?) For efficiency and stability, we use the EMalgorithm to find??, rather than L-BFGS as in (Foster et al., 2010)","For efficiency and stability, we use the EM algorithm to find ?, rather than L-BFGS as in (Foster et al., 2010)","'75','70','68','2','3','152','17','137'","<S sid=""75"" ssid=""12"">However, it is robust, efficient, and easy to implement.4 To perform the maximization in (7), we used the popular L-BFGS algorithm (Liu and Nocedal, 1989), which requires gradient information.</S><S sid=""70"" ssid=""7"">Second, rather than relying on a division of the corpus into manually-assigned portions, we use features intended to capture the usefulness of each phrase pair.</S><S sid=""68"" ssid=""5"">First, we learn weights on individual phrase pairs rather than sentences.</S><S sid=""2"" ssid=""2"">This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure.</S><S sid=""3"" ssid=""3"">We incorporate instance weighting into a mixture-model framework, and find that it yields consistent improvements over a wide range of baselines.</S><S sid=""152"" ssid=""9"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S><S sid=""17"" ssid=""14"">Previous approaches have tried to find examples that are similar to the target domain.</S><S sid=""137"" ssid=""6"">At first glance, this seems only peripherally related to our work, since the specific/general distinction is made for features rather than instances.</S>",['method_citation']
13,D10-1044,P12-1099,0,2010,0,"Foster et al (2010), however, uses a different approach to select related sentences from OUT","Foster et al (2010), however, uses a different approach to select related sentences from OUT","'31','42','149','152','6'","<S sid=""31"" ssid=""28"">For comparison to information-retrieval inspired baselines, eg (L&#168;u et al., 2007), we select sentences from OUT using language model perplexities from IN.</S><S sid=""42"" ssid=""6"">The natural baseline approach is to concatenate data from IN and OUT.</S><S sid=""149"" ssid=""6"">We obtained positive results using a very simple phrase-based system in two different adaptation settings: using English/French Europarl to improve a performance on a small, specialized medical domain; and using non-news portions of the NIST09 training material to improve performance on the news-related corpora.</S><S sid=""152"" ssid=""9"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S><S sid=""6"" ssid=""3"">Realizing gains in practice can be challenging, however, particularly when the target domain is distant from the background data.</S>","['method_citation','results_citation']"
14,D10-1044,P12-1099,0,2010,0,Foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,Foster et al (2010) propose a similar method for machine translation that uses features to capture degrees of generality,"'22','0','153','7','21','70','40'","<S sid=""22"" ssid=""19"">Within this framework, we use features intended to capture degree of generality, including the output from an SVM classifier that uses the intersection between IN and OUT as positive examples.</S><S sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S><S sid=""153"" ssid=""10"">Finally, we intend to explore more sophisticated instanceweighting features for capturing the degree of generality of phrase pairs.</S><S sid=""7"" ssid=""4"">For developers of Statistical Machine Translation (SMT) systems, an additional complication is the heterogeneous nature of SMT components (word-alignment model, language model, translation model, etc.</S><S sid=""21"" ssid=""18"">This highly effective approach is not directly applicable to the multinomial models used for core SMT components, which have no natural method for combining split features, so we rely on an instance-weighting approach (Jiang and Zhai, 2007) to downweight domain-specific examples in OUT.</S><S sid=""70"" ssid=""7"">Second, rather than relying on a division of the corpus into manually-assigned portions, we use features intended to capture the usefulness of each phrase pair.</S><S sid=""40"" ssid=""4"">We focus here instead on adapting the two most important features: the language model (LM), which estimates the probability p(wIh) of a target word w following an ngram h; and the translation models (TM) p(slt) and p(t1s), which give the probability of source phrase s translating to target phrase t, and vice versa.</S>","['method_citation','results_citation']"
15,D10-1044,P13-1126,0,"Foster et al, 2010",0,"As in (Foster et al, 2010), this approach works at the level of phrase pairs","As in (Foster et al, 2010), this approach works at the level of phrase pairs","'23','26','1','144','152'","<S sid=""23"" ssid=""20"">Our second contribution is to apply instance weighting at the level of phrase pairs.</S><S sid=""26"" ssid=""23"">Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009), who weight sentences according to sub-corpus and genre membership.</S><S sid=""1"" ssid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S sid=""144"" ssid=""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid=""152"" ssid=""9"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S>",['method_citation']
16,D10-1044,D11-1033,0,2010,0,"The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","'0','1','62','9','142','24'","<S sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S><S sid=""1"" ssid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S sid=""62"" ssid=""26"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S sid=""9"" ssid=""6"">In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material&#8212;though adequate for reasonable performance&#8212;is also available.</S><S sid=""142"" ssid=""11"">There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007).</S><S sid=""24"" ssid=""21"">Sentence pairs are the natural instances for SMT, but sentences often contain a mix of domain-specific and general language.</S>",['method_citation']
17,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance","Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance","'42','119','144','9','5','31'","<S sid=""42"" ssid=""6"">The natural baseline approach is to concatenate data from IN and OUT.</S><S sid=""119"" ssid=""23"">The 2nd block contains the IR system, which was tuned by selecting text in multiples of the size of the EMEA training corpus, according to dev set performance.</S><S sid=""144"" ssid=""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid=""9"" ssid=""6"">In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material&#8212;though adequate for reasonable performance&#8212;is also available.</S><S sid=""5"" ssid=""2"">Even when there is training data available in the domain of interest, there is often additional data from other domains that could in principle be used to improve performance.</S><S sid=""31"" ssid=""28"">For comparison to information-retrieval inspired baselines, eg (L&#168;u et al., 2007), we select sentences from OUT using language model perplexities from IN.</S>","['method_citation','results_citation']"
18,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","'28','68','95','24','152','113','23'","<S sid=""28"" ssid=""25"">We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.</S><S sid=""68"" ssid=""5"">First, we learn weights on individual phrase pairs rather than sentences.</S><S sid=""95"" ssid=""32"">Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models), and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples, with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set.</S><S sid=""24"" ssid=""21"">Sentence pairs are the natural instances for SMT, but sentences often contain a mix of domain-specific and general language.</S><S sid=""152"" ssid=""9"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S><S sid=""113"" ssid=""17"">The corpus was wordaligned using both HMM and IBM2 models, and the phrase table was the union of phrases extracted from these separate alignments, with a length limit of 7.</S><S sid=""23"" ssid=""20"">Our second contribution is to apply instance weighting at the level of phrase pairs.</S>","['method_citation','results_citation']"
19,D10-1044,P14-1012,0,"Foster et al, 2010",0,"To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","'94','65','40','1','89','145'","<S sid=""94"" ssid=""31"">In addition to using the simple features directly, we also trained an SVM classifier with these features to distinguish between IN and OUT phrase pairs.</S><S sid=""65"" ssid=""2"">Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities.</S><S sid=""40"" ssid=""4"">We focus here instead on adapting the two most important features: the language model (LM), which estimates the probability p(wIh) of a target word w following an ngram h; and the translation models (TM) p(slt) and p(t1s), which give the probability of source phrase s translating to target phrase t, and vice versa.</S><S sid=""1"" ssid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S sid=""89"" ssid=""26"">We used 22 features for the logistic weighting model, divided into two groups: one intended to reflect the degree to which a phrase pair belongs to general language, and one intended to capture similarity to the IN domain.</S><S sid=""145"" ssid=""2"">Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be.</S>",['method_citation']
