Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,W99-0613,N01-1023,0,"Collins and Singer, 1999",0,"Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)","Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)","'121','28','1','9','0','16'","<S sid=""121"" ssid=""54"">They also describe an application of cotraining to classifying web pages (the to feature sets are the words on the page, and other pages pointing to the page).</S><S sid=""28"" ssid=""22"">(Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance.</S><S sid=""1"" ssid=""1"">This paper discusses the use of unlabeled examples for the problem of named entity classification.</S><S sid=""9"" ssid=""3"">This paper discusses the use of unlabeled examples for the problem of named entity classification.</S><S sid=""0"">Unsupervised Models for Named Entity Classification Collins</S><S sid=""16"" ssid=""10"">Supervised methods have been applied quite successfully to the full MUC named-entity task (Bikel et al. 97).</S>",['method_citation']
2,W99-0613,N01-1023,0,"Collins and Singer, 1999",0,"They also discuss an application of classifying web pages by using their method of mutually constrained models. (Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toAdaBoost which force the classifiers to agree (called Co Boosting)","(Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms to AdaBoost which force the classifiers to agree (called Co Boosting)","'174','137','33','247','140','35'","<S sid=""174"" ssid=""41"">The two new terms force the two classifiers to agree, as much as possible, on the unlabeled examples.</S><S sid=""137"" ssid=""4"">The new algorithm, which we call CoBoost, uses labeled and unlabeled data and builds two classifiers in parallel.</S><S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S><S sid=""247"" ssid=""14"">N, portion of examples on which both classifiers give a label rather than abstaining), and the proportion of these examples on which the two classifiers agree.</S><S sid=""140"" ssid=""7"">AdaBoost was first introduced in (Freund and Schapire 97); (Schapire and Singer 98) gave a generalization of AdaBoost which we will use in this paper.</S><S sid=""35"" ssid=""29"">AdaBoost finds a weighted combination of simple (weak) classifiers, where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.</S>",['method_citation']
3,W99-0613,W03-1509,0,Collins and Singer 1999,0,"Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on","Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on","'91','127','220','134','138','132','192'","<S sid=""91"" ssid=""24"">There are two differences between this method and the DL-CoTrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features.</S><S sid=""127"" ssid=""60"">The DL-CoTrain algorithm can be motivated as being a greedy method of satisfying the above 2 constraints.</S><S sid=""220"" ssid=""87"">(7), such as the likelihood function used in maximum-entropy problems and other generalized additive models (Lafferty 99).</S><S sid=""134"" ssid=""1"">This section describes an algorithm based on boosting algorithms, which were previously developed for supervised machine learning problems.</S><S sid=""138"" ssid=""5"">(We would like to note though that unlike previous boosting algorithms, the CoBoost algorithm presented here is not a boosting algorithm under Valiant's (Valiant 84) Probably Approximately Correct (PAC) model.)</S><S sid=""132"" ssid=""65"">The algorithm, called CoBoost, has the advantage of being more general than the decision-list learning alInput: (xi , yi), , (xim, ) ; x, E 2x, yi = +1 Initialize Di (i) = 1/m.</S><S sid=""192"" ssid=""59"">On each step CoBoost searches for a feature and a weight so as to minimize either 40 or 40.</S>","['implication_citation','method_citation']"
4,W99-0613,C02-1154,0,"Collins and Singer, 1999",0,"DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syn tactically analyzed corpus","DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syntactically analyzed corpus","'10','79','91','127','214','40','41','14','254'","<S sid=""10"" ssid=""4"">The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location.</S><S sid=""79"" ssid=""12"">2 We now introduce a new algorithm for learning from unlabeled examples, which we will call DLCoTrain (DL stands for decision list, the term Cotrain is taken from (Blum and Mitchell 98)).</S><S sid=""91"" ssid=""24"">There are two differences between this method and the DL-CoTrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features.</S><S sid=""127"" ssid=""60"">The DL-CoTrain algorithm can be motivated as being a greedy method of satisfying the above 2 constraints.</S><S sid=""214"" ssid=""81"">This modification brings the method closer to the DL-CoTrain algorithm described earlier, and is motivated by the intuition that all three labels should be kept healthily populated in the unlabeled examples, preventing one label from dominating &#8212; this deserves more theoretical investigation.</S><S sid=""40"" ssid=""34"">(Berland and Charniak 99) describe a method for extracting parts of objects from wholes (e.g., &amp;quot;speedometer&amp;quot; from &amp;quot;car&amp;quot;) from a large corpus using hand-crafted patterns.</S><S sid=""41"" ssid=""35"">(Hearst 92) describes a method for extracting hyponyms from a corpus (pairs of words in &amp;quot;isa&amp;quot; relations).</S><S sid=""14"" ssid=""8"">A contextual rule considers words surrounding the string in the sentence in which it appears (e.g., a rule that any proper name modified by an appositive whose head is president is a person).</S><S sid=""254"" ssid=""5"">Future work should also extend the approach to build a complete named entity extractor - a method that pulls proper names from text and then classifies them.</S>","['implication_citation','method_citation','results_citation']"
5,W99-0613,C02-1154,0,"Collins and Singer, 1999",0,"(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify","(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances it set out to classify","'10','237','236','77','213','199','11'","<S sid=""10"" ssid=""4"">The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location.</S><S sid=""237"" ssid=""4"">The numbers falling into the location, person, organization categories were 186, 289 and 402 respectively.</S><S sid=""236"" ssid=""3"">We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.</S><S sid=""77"" ssid=""10"">In this paper k = 3 (the three labels are person, organization, location), and we set a = 0.1.</S><S sid=""213"" ssid=""80"">Thus at each iteration the algorithm is forced to pick features for the location, person and organization in turn for the classifier being trained.</S><S sid=""199"" ssid=""66"">Thus corresponding pseudo-labels for instances on which gj abstain are set to zero and these instances do not contribute to the objective function.</S><S sid=""11"" ssid=""5"">For example, a good classifier would identify Mrs. Frank as a person, Steptoe &amp; Johnson as a company, and Honduras as a location.</S>","['implication_citation','method_citation']"
6,W99-0613,W06-2204,0,"Collins and Singer, 1999",0,"In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification","In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification","'18','250','2','0','8','1','9','47'","<S sid=""18"" ssid=""12"">But we will show that the use of unlabeled data can drastically reduce the need for supervision.</S><S sid=""250"" ssid=""1"">Unlabeled examples in the named-entity classification problem can reduce the need for supervision to a handful of seed rules.</S><S sid=""2"" ssid=""2"">A large number of rules is needed for coverage of the domain, suggesting that a fairly large number of labeled examples should be required to train a classi- However, we show that the use of data can reduce the requirements for supervision to just 7 simple &amp;quot;seed&amp;quot; rules.</S><S sid=""0"">Unsupervised Models for Named Entity Classification Collins</S><S sid=""8"" ssid=""2"">Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.</S><S sid=""1"" ssid=""1"">This paper discusses the use of unlabeled examples for the problem of named entity classification.</S><S sid=""9"" ssid=""3"">This paper discusses the use of unlabeled examples for the problem of named entity classification.</S><S sid=""47"" ssid=""1"">971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN).</S>",[]
8,W99-0613,W03-1022,0,"Collins and Singer, 1999",0,"Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)","Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)","'236','256','77','3','202'","<S sid=""236"" ssid=""3"">We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.</S><S sid=""256"" ssid=""7"">The problem of &amp;quot;noise&amp;quot; items that do not fall into any of the three categories also needs to be addressed.</S><S sid=""77"" ssid=""10"">In this paper k = 3 (the three labels are person, organization, location), and we set a = 0.1.</S><S sid=""3"" ssid=""3"">The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type.</S><S sid=""202"" ssid=""69"">The CoBoost algorithm just described is for the case where there are two labels: for the named entity task there are three labels, and in general it will be useful to generalize the CoBoost algorithm to the multiclass case.</S>","['implication_citation','method_citation']"
9,W99-0613,E09-1018,0,"Collinsand Singer, 1999",0,"While EM has worked quite well for a few tasks, notably ma chine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)","While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)","'3','0','16','57'","<S sid=""3"" ssid=""3"">The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type.</S><S sid=""0"">Unsupervised Models for Named Entity Classification Collins</S><S sid=""16"" ssid=""10"">Supervised methods have been applied quite successfully to the full MUC named-entity task (Bikel et al. 97).</S><S sid=""57"" ssid=""11"">From here on we will refer to the named-entity string itself as the spelling of the entity, and the contextual predicate as the context.</S>",['method_citation']
11,W99-0613,W07-1712,0,"Collins and Singer, 1999",0,"In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)","In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)","'251','138','219','29','55','30'","<S sid=""251"" ssid=""2"">In addition to a heuristic based on decision list learning, we also presented a boosting-like framework that builds on ideas from (Blum and Mitchell 98).</S><S sid=""138"" ssid=""5"">(We would like to note though that unlike previous boosting algorithms, the CoBoost algorithm presented here is not a boosting algorithm under Valiant's (Valiant 84) Probably Approximately Correct (PAC) model.)</S><S sid=""219"" ssid=""86"">Finally, we would like to note that it is possible to devise similar algorithms based with other objective functions than the one given in Equ.</S><S sid=""29"" ssid=""23"">Unfortunately, Yarowsky's method is not well understood from a theoretical viewpoint: we would like to formalize the notion of redundancy in unlabeled data, and set up the learning task as optimization of some appropriate objective function.</S><S sid=""55"" ssid=""9"">In addition to the named-entity string (Maury Cooper or Georgia), a contextual predictor was also extracted.</S><S sid=""30"" ssid=""24"">(Blum and Mitchell 98) offer a promising formulation of redundancy, also prove some results about how the use of unlabeled examples can help classification, and suggest an objective function when training with unlabeled examples.</S>",[]
12,W99-0613,W09-2208,0,"Collins and Singer, 1999",0,"Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky ?smethod (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)","Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky's method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)","'6','68','5','8','27','91'","<S sid=""6"" ssid=""6"">The second algorithm extends ideas from boosting algorithms, designed for supervised learning tasks, to the framework suggested by (Blum and Mitchell 98).</S><S sid=""68"" ssid=""1"">The first unsupervised algorithm we describe is based on the decision list method from (Yarowsky 95).</S><S sid=""5"" ssid=""5"">The first method uses a similar algorithm to that of (Yarowsky 95), with modifications motivated by (Blum and Mitchell 98).</S><S sid=""8"" ssid=""2"">Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.</S><S sid=""27"" ssid=""21"">The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).</S><S sid=""91"" ssid=""24"">There are two differences between this method and the DL-CoTrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features.</S>",['method_citation']
13,W99-0613,W06-2207,0,"Collins and Singer, 1999",0,"This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)","This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)","'7','39','3','32','169','29'","<S sid=""7"" ssid=""1"">Many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.</S><S sid=""39"" ssid=""33"">(Brin 98) ,describes a system for extracting (author, book-title) pairs from the World Wide Web using an approach that bootstraps from an initial seed set of examples.</S><S sid=""3"" ssid=""3"">The approach gains leverage from natural redundancy in the data: for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type.</S><S sid=""32"" ssid=""26"">The algorithm can be viewed as heuristically optimizing an objective function suggested by (Blum and Mitchell 98); empirically it is shown to be quite successful in optimizing this criterion.</S><S sid=""169"" ssid=""36"">(3)) to be defined over unlabeled as well as labeled instances.</S><S sid=""29"" ssid=""23"">Unfortunately, Yarowsky's method is not well understood from a theoretical viewpoint: we would like to formalize the notion of redundancy in unlabeled data, and set up the learning task as optimization of some appropriate objective function.</S>",['method_citation']
15,W99-0613,W06-2207,0,"Collins and Singer, 1999",0,"(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here","(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here","'85','57','230','209','162'","<S sid=""85"" ssid=""18"">(If fewer than n rules have Precision greater than pin, we 3Note that taking tlie top n most frequent rules already makes the method robut to low count events, hence we do not use smoothing, allowing low-count high-precision features to be chosen on later iterations. keep only those rules which exceed the precision threshold.) pm,n was fixed at 0.95 in all experiments in this paper.</S><S sid=""57"" ssid=""11"">From here on we will refer to the named-entity string itself as the spelling of the entity, and the contextual predicate as the context.</S><S sid=""230"" ssid=""9"">In our experiments we set the parameter values randomly, and then ran EM to convergence.</S><S sid=""209"" ssid=""76"">For the experiments in this paper we made a couple of additional modifications to the CoBoost algorithm.</S><S sid=""162"" ssid=""29"">(6), with W+ &gt; W_.</S>",['method_citation']
16,W99-0613,P12-1065,0,1999,0,We use Collins and Singer (1999) for our exact specification of Yarowsky.2 It uses DL rule scores ?fj?| ?fj |+ |? f |+ L (1) where  is a smoothing constant,We use Collins and Singer (1999) for our exact specification of Yarowsky,"'31','46','80','154','230','68','156'","<S sid=""31"" ssid=""25"">Our first algorithm is similar to Yarowsky's, but with some important modifications motivated by (Blum and Mitchell 98).</S><S sid=""46"" ssid=""40"">(Riloff and Jones 99) was brought to our attention as we were preparing the final version of this paper.</S><S sid=""80"" ssid=""13"">The 2(Yarowsky 95) describes the use of more sophisticated smoothing methods.</S><S sid=""154"" ssid=""21"">In our implementation, we make perhaps the simplest choice of weak hypothesis.</S><S sid=""230"" ssid=""9"">In our experiments we set the parameter values randomly, and then ran EM to convergence.</S><S sid=""68"" ssid=""1"">The first unsupervised algorithm we describe is based on the decision list method from (Yarowsky 95).</S><S sid=""156"" ssid=""23"">Our derivation is slightly different from the one presented in (Schapire and Singer 98) as we restrict at to be positive.</S>",['method_citation']
